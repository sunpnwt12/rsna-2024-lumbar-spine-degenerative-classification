{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b401ee",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:18.605006Z",
     "iopub.status.busy": "2024-09-23T15:40:18.604695Z",
     "iopub.status.idle": "2024-09-23T15:40:27.465935Z",
     "shell.execute_reply": "2024-09-23T15:40:27.465161Z"
    },
    "papermill": {
     "duration": 8.874623,
     "end_time": "2024-09-23T15:40:27.468300",
     "exception": false,
     "start_time": "2024-09-23T15:40:18.593677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedGroupKFold, GroupKFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import pandas.api.types\n",
    "import sklearn.metrics\n",
    "\n",
    "import timm\n",
    "import transformers\n",
    "import pydicom\n",
    "import cv2\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ec7bf",
   "metadata": {
    "papermill": {
     "duration": 0.008872,
     "end_time": "2024-09-23T15:40:27.486911",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.478039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac31b5c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.506394Z",
     "iopub.status.busy": "2024-09-23T15:40:27.505866Z",
     "iopub.status.idle": "2024-09-23T15:40:27.511104Z",
     "shell.execute_reply": "2024-09-23T15:40:27.510257Z"
    },
    "papermill": {
     "duration": 0.01703,
     "end_time": "2024-09-23T15:40:27.512995",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.495965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82af95",
   "metadata": {
    "papermill": {
     "duration": 0.00933,
     "end_time": "2024-09-23T15:40:27.531527",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.522197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3d2813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.551688Z",
     "iopub.status.busy": "2024-09-23T15:40:27.551378Z",
     "iopub.status.idle": "2024-09-23T15:40:27.555720Z",
     "shell.execute_reply": "2024-09-23T15:40:27.554810Z"
    },
    "papermill": {
     "duration": 0.016093,
     "end_time": "2024-09-23T15:40:27.557556",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.541463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def split_fold(conf, df_):\n",
    "#     print('split fold..')\n",
    "#     df = df_.clone()\n",
    "    \n",
    "#     sgkf = StratifiedGroupKFold(n_splits=conf.fold_num, shuffle=True, random_state=conf.seed)\n",
    "#     splitter = np.zeros(df.height)\n",
    "    \n",
    "#     for fold, (_, valid_idx) in enumerate(sgkf.split(X=df['study_id'], y=df['level'], groups=df['study_id'])):\n",
    "#         splitter[valid_idx] = fold\n",
    "    \n",
    "#     df = df.with_columns(fold=pl.Series(splitter).cast(pl.Int8))\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f50bbe",
   "metadata": {
    "papermill": {
     "duration": 0.009305,
     "end_time": "2024-09-23T15:40:27.576096",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.566791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f879bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.596811Z",
     "iopub.status.busy": "2024-09-23T15:40:27.596515Z",
     "iopub.status.idle": "2024-09-23T15:40:27.628655Z",
     "shell.execute_reply": "2024-09-23T15:40:27.627805Z"
    },
    "papermill": {
     "duration": 0.044379,
     "end_time": "2024-09-23T15:40:27.630592",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.586213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSDCTrainDataset(Dataset):\n",
    "    def __init__(self, conf, df, study_id_level_df, patient_coords, axial_IPP, transforms):\n",
    "        super().__init__()\n",
    "        self.conf = conf\n",
    "        self.df = df\n",
    "        self.study_id_level_df = study_id_level_df\n",
    "        self.patient_coords = patient_coords\n",
    "        self.axial_IPP = axial_IPP\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.label_names_cond = [\n",
    "            # sagittal_t1\n",
    "            'left_neural_foraminal_narrowing_normal_mild',\n",
    "            'left_neural_foraminal_narrowing_moderate',\n",
    "            'left_neural_foraminal_narrowing_severe',\n",
    "\n",
    "            'right_neural_foraminal_narrowing_normal_mild',\n",
    "            'right_neural_foraminal_narrowing_moderate',\n",
    "            'right_neural_foraminal_narrowing_severe',\n",
    "\n",
    "            # sagittal_t2\n",
    "            'spinal_canal_stenosis_normal_mild',\n",
    "            'spinal_canal_stenosis_moderate',\n",
    "            'spinal_canal_stenosis_severe',\n",
    "\n",
    "            # axial\n",
    "            'left_subarticular_stenosis_normal_mild',\n",
    "            'left_subarticular_stenosis_moderate',\n",
    "            'left_subarticular_stenosis_severe',\n",
    "\n",
    "            'right_subarticular_stenosis_normal_mild',\n",
    "            'right_subarticular_stenosis_moderate',\n",
    "            'right_subarticular_stenosis_severe',\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.study_id_level_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_stack = np.zeros((self.conf.image_size, self.conf.image_size, self.conf.n_slices))\n",
    "        chan = 0\n",
    "\n",
    "        study_id_level_samples = self.study_id_level_df[idx]\n",
    "        this_study_lvl = self.df.filter(pl.col('study_id_level') == study_id_level_samples)\n",
    "        this_study = this_study_lvl['study_id'].item(0)\n",
    "        sagittal_t1 = this_study_lvl.filter(pl.col('series_description') == 'Sagittal T1')\n",
    "        sagittal_t2 = this_study_lvl.filter(pl.col('series_description') == 'Sagittal T2/STIR')\n",
    "        axial_t2 = this_study_lvl.filter(pl.col('series_description') == 'Axial T2')\n",
    "        labels = this_study_lvl.select(self.label_names_cond).to_numpy()[0]\n",
    "\n",
    "        if not sagittal_t1.is_empty():\n",
    "            sagittal_t1_path = sagittal_t1['series_path'].item(0)\n",
    "            sagittal_t1_slices = sagittal_t1['slices'][0].to_numpy()\n",
    "            sagittal_t1_coords = sagittal_t1.select(['x', 'y']).to_numpy().mean(axis=0)\n",
    "\n",
    "            for ins_num in sagittal_t1_slices:\n",
    "\n",
    "                dicom = np.load(f'{sagittal_t1_path}/{ins_num}.npy')\n",
    "                window_half_size = (np.mean(dicom.shape) * self.conf.sagittal_window_ratio) // 2\n",
    "                cropped = dicom[\n",
    "                    round(sagittal_t1_coords[1] - window_half_size): round(sagittal_t1_coords[1] + window_half_size),\n",
    "                    round(sagittal_t1_coords[0] - window_half_size): round(sagittal_t1_coords[0] + window_half_size),\n",
    "                ]\n",
    "                image_stack[:, :, chan] = cv2.resize(cropped, (self.conf.image_size, self.conf.image_size))\n",
    "                chan += 1\n",
    "        else:\n",
    "            chan += 11 # skip if study does not have sagittal t1\n",
    "\n",
    "        if not sagittal_t2.is_empty():\n",
    "\n",
    "            sagittal_t2_path = sagittal_t2['series_path'].item(0)\n",
    "            sagittal_t2_slices = sagittal_t2['slices'][0].to_numpy()\n",
    "            sagittal_t2_coords = sagittal_t2.select(['x', 'y']).to_numpy().mean(axis=0)\n",
    "\n",
    "            for ins_num in sagittal_t2_slices:\n",
    "\n",
    "                dicom = np.load(f'{sagittal_t2_path}/{ins_num}.npy')\n",
    "                window_half_size = (np.mean(dicom.shape) * self.conf.sagittal_window_ratio) // 2\n",
    "                cropped = dicom[\n",
    "                    round(sagittal_t2_coords[1] - window_half_size): round(sagittal_t2_coords[1] + window_half_size),\n",
    "                    round(sagittal_t2_coords[0] - window_half_size): round(sagittal_t2_coords[0] + window_half_size),\n",
    "                ]\n",
    "                image_stack[:, :, chan] = cv2.resize(cropped, (self.conf.image_size, self.conf.image_size))\n",
    "                chan += 1\n",
    "\n",
    "            # can not cross-ref if sagittal t2 does not exist\n",
    "            if not axial_t2.is_empty():\n",
    "                axial_t2_path = axial_t2['series_path'].item(0)\n",
    "                axial_t2_slices = axial_t2['slices'][0].to_numpy()\n",
    "                axial_t2_coords = axial_t2.select(['x', 'y']).to_numpy().mean(axis=0)\n",
    "\n",
    "                axial_z_axis = self.axial_IPP.filter(pl.col('study_id') == this_study)[['instance_number', 'SliceLocation']].to_numpy()\n",
    "                sag_coord = self.patient_coords.filter(\n",
    "                    pl.col('study_id_level') == study_id_level_samples,\n",
    "                    pl.col('series_description') == 'Sagittal T2/STIR'\n",
    "                )['patient_coords'].to_numpy()[0]\n",
    "\n",
    "                level_idx = self._find_axial(axial_z_axis, sag_coord, self.conf.axial_min_dist_threshold)\n",
    "                if level_idx is not None:\n",
    "                    level_pack_slices = axial_t2_slices[\n",
    "                        level_idx - 2: level_idx + 1\n",
    "                    ]\n",
    "\n",
    "                    for ins_num in level_pack_slices:\n",
    "                        dicom = np.load(f'{axial_t2_path}/{ins_num}.npy')\n",
    "                        window_half_size = (np.mean(dicom.shape) * self.conf.axial_window_ratio) // 2\n",
    "                        cropped = dicom[\n",
    "                            round(axial_t2_coords[1] - window_half_size): round(axial_t2_coords[1] + window_half_size),\n",
    "                            round(axial_t2_coords[0] - window_half_size): round(axial_t2_coords[0] + window_half_size),\n",
    "                        ]\n",
    "#                         cropped = self._center_crop(dicom, (self.conf.axial_center_crop_size, self.conf.axial_center_crop_size))\n",
    "                        image_stack[:, :, chan] = cv2.resize(cropped, (self.conf.image_size, self.conf.image_size))\n",
    "                        chan += 1\n",
    "\n",
    "        image_stack = (image_stack - image_stack.min()) / (image_stack.max() - image_stack.min())\n",
    "        image_stack = image_stack.astype(np.float32)\n",
    "\n",
    "        new_image_stack = np.concatenate([\n",
    "            # left\n",
    "            image_stack[:, :, 0: 3], # T1\n",
    "            image_stack[:, :, 11: 14], # T2\n",
    "            # middle\n",
    "            image_stack[:, :, 3: 8], # T1\n",
    "            image_stack[:, :, 14: 19], # T2\n",
    "            # right\n",
    "            image_stack[:, :, 8: 11], # T1\n",
    "            image_stack[:, :, 19: 22], # T2\n",
    "            # axial\n",
    "            image_stack[:, :, 22: 25],\n",
    "        ], axis=-1)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            new_image_stack = self.transforms(image=new_image_stack)['image']\n",
    "\n",
    "        batch = {}\n",
    "        batch['study_id_level'] = study_id_level_samples\n",
    "        batch['images'] = new_image_stack.to(dtype=torch.float)\n",
    "        batch['labels'] = torch.as_tensor(labels, dtype=torch.float)\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def _read_dcm(self, path):\n",
    "        data = pydicom.dcmread(path).pixel_array\n",
    "        return data\n",
    "\n",
    "    def _center_crop(self, img, dim):\n",
    "        # https://gist.github.com/Nannigalaxy/35dd1d0722f29672e68b700bc5d44767\n",
    "        \"\"\"Returns center cropped image\n",
    "        Args:\n",
    "        img: image to be center cropped\n",
    "        dim: dimensions (width, height) to be cropped\n",
    "        \"\"\"\n",
    "        width, height = img.shape[1], img.shape[0]\n",
    "\n",
    "        # process crop width and height for max available dimension\n",
    "        crop_width = dim[0] if dim[0] < img.shape[1] else img.shape[1]\n",
    "        crop_height = dim[1] if dim[1] < img.shape[0] else img.shape[0]\n",
    "        mid_x, mid_y = int(width / 2), int(height / 2)\n",
    "        cw2, ch2 = int(crop_width / 2), int(crop_height / 2)\n",
    "        crop_img = img[mid_y - ch2: mid_y + ch2, mid_x - cw2: mid_x + cw2]\n",
    "        return crop_img\n",
    "\n",
    "    def _find_axial(self, axial_array, sag_coords, threshold):\n",
    "        # axial_array (instance, IPP-z)\n",
    "        slice_position = axial_array[:, 1] # axial z-axis\n",
    "        distance = np.abs(slice_position - sag_coords[2])\n",
    "        slice_pos = np.argmin(distance)\n",
    "\n",
    "        if threshold != None:\n",
    "            if axial_array[slice_pos][1] > threshold:\n",
    "                return None\n",
    "\n",
    "        return int(axial_array[slice_pos][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6529d7f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.650228Z",
     "iopub.status.busy": "2024-09-23T15:40:27.649943Z",
     "iopub.status.idle": "2024-09-23T15:40:27.653677Z",
     "shell.execute_reply": "2024-09-23T15:40:27.652799Z"
    },
    "papermill": {
     "duration": 0.015595,
     "end_time": "2024-09-23T15:40:27.655526",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.639931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample = train_df.sample().item(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be25dca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.674994Z",
     "iopub.status.busy": "2024-09-23T15:40:27.674739Z",
     "iopub.status.idle": "2024-09-23T15:40:27.678796Z",
     "shell.execute_reply": "2024-09-23T15:40:27.678076Z"
    },
    "papermill": {
     "duration": 0.015914,
     "end_time": "2024-09-23T15:40:27.680671",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.664757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = data_preprocess(CONF, train_df.filter(pl.col('study_id') == sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af3e5ec4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.700813Z",
     "iopub.status.busy": "2024-09-23T15:40:27.700287Z",
     "iopub.status.idle": "2024-09-23T15:40:27.703777Z",
     "shell.execute_reply": "2024-09-23T15:40:27.702964Z"
    },
    "papermill": {
     "duration": 0.015545,
     "end_time": "2024-09-23T15:40:27.705576",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.690031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# conf = CONF()\n",
    "# dataset = LSDCTrainDataset(conf, df, df['study_id_level'].unique(maintain_order=True), patient_coords, axial_IPP, get_transforms(CONF, types='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eda9e2c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.725607Z",
     "iopub.status.busy": "2024-09-23T15:40:27.725349Z",
     "iopub.status.idle": "2024-09-23T15:40:27.728707Z",
     "shell.execute_reply": "2024-09-23T15:40:27.727937Z"
    },
    "papermill": {
     "duration": 0.015219,
     "end_time": "2024-09-23T15:40:27.730594",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.715375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96bcdbd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.750435Z",
     "iopub.status.busy": "2024-09-23T15:40:27.750175Z",
     "iopub.status.idle": "2024-09-23T15:40:27.753794Z",
     "shell.execute_reply": "2024-09-23T15:40:27.753044Z"
    },
    "papermill": {
     "duration": 0.015558,
     "end_time": "2024-09-23T15:40:27.755624",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.740066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(data['study_id_level'])\n",
    "# print(data['labels'].view(5, 3))\n",
    "# fig = plt.figure(figsize=(20, 20))\n",
    "# for i, img in enumerate(data['images']):\n",
    "#     num = i + 1\n",
    "#     ax = fig.add_subplot(5, 5, num, frameon=False)\n",
    "#     ax.title.set_text(num)\n",
    "#     plt.imshow(img, cmap='gray')\n",
    "#     plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec613f",
   "metadata": {
    "papermill": {
     "duration": 0.009464,
     "end_time": "2024-09-23T15:40:27.774772",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.765308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "150e8c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.794657Z",
     "iopub.status.busy": "2024-09-23T15:40:27.794398Z",
     "iopub.status.idle": "2024-09-23T15:40:27.801979Z",
     "shell.execute_reply": "2024-09-23T15:40:27.801153Z"
    },
    "papermill": {
     "duration": 0.019717,
     "end_time": "2024-09-23T15:40:27.803901",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.784184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms(conf, types):\n",
    "    tranforms_dict = {\n",
    "        'train': A.Compose([\n",
    "#             A.VerticalFlip(p=0.5),\n",
    "#             A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.25, rotate_limit=25, border_mode=4, p=0.7),\n",
    "            A.RandomBrightnessContrast(p=0.7),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=3),\n",
    "                A.MedianBlur(blur_limit=3),\n",
    "                A.GaussianBlur(blur_limit=3),\n",
    "                A.GaussNoise(var_limit=(3.0, 9.0)),\n",
    "            ], p=0.5),\n",
    "            A.OneOf([\n",
    "                A.OpticalDistortion(distort_limit=1.),\n",
    "                A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "            ], p=0.5),\n",
    "            A.CoarseDropout(max_height=int(conf.image_size * 0.1), max_width=int(conf.image_size * 0.1), max_holes=4, fill_value=0., p=0.5),\n",
    "            ToTensorV2(),\n",
    "        ]),\n",
    "\n",
    "        'valid': A.Compose([\n",
    "            ToTensorV2(),\n",
    "        ]),\n",
    "        'check': A.Compose([\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.05, always_apply=True),\n",
    "            ToTensorV2(),\n",
    "        ]),\n",
    "    }\n",
    "    return tranforms_dict[types]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bac6259",
   "metadata": {
    "papermill": {
     "duration": 0.009238,
     "end_time": "2024-09-23T15:40:27.822750",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.813512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e66831f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.842661Z",
     "iopub.status.busy": "2024-09-23T15:40:27.842396Z",
     "iopub.status.idle": "2024-09-23T15:40:27.849458Z",
     "shell.execute_reply": "2024-09-23T15:40:27.848653Z"
    },
    "papermill": {
     "duration": 0.019186,
     "end_time": "2024-09-23T15:40:27.851314",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.832128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26f131cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.871422Z",
     "iopub.status.busy": "2024-09-23T15:40:27.871150Z",
     "iopub.status.idle": "2024-09-23T15:40:27.880103Z",
     "shell.execute_reply": "2024-09-23T15:40:27.879286Z"
    },
    "papermill": {
     "duration": 0.02118,
     "end_time": "2024-09-23T15:40:27.882077",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.860897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/bminixhofer/a-validation-framework-impact-of-the-random-seed\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking = True\n",
    "\n",
    "        self.bias = bias\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        \n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.xavier_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        \n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        feature_dim = self.feature_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim), \n",
    "            self.weight\n",
    "        ).view(-1, step_dim)\n",
    "        \n",
    "        if self.bias:\n",
    "            eij = eij + self.b\n",
    "            \n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        \n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "\n",
    "        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n",
    "\n",
    "        weighted_input = x * torch.unsqueeze(a, -1)\n",
    "        return torch.sum(weighted_input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4586e69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.902854Z",
     "iopub.status.busy": "2024-09-23T15:40:27.902593Z",
     "iopub.status.idle": "2024-09-23T15:40:27.934271Z",
     "shell.execute_reply": "2024-09-23T15:40:27.933408Z"
    },
    "papermill": {
     "duration": 0.04443,
     "end_time": "2024-09-23T15:40:27.936299",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.891869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSDCModel(nn.Module):\n",
    "    def __init__(self, conf, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.head_type = conf.head_type\n",
    "        if self.head_type == 'lstm_attn':\n",
    "            self.head_feats = 512\n",
    "        elif self.head_type == 'lstm_mean_max':\n",
    "            self.head_feats = 512 * 2\n",
    "        elif self.head_type == 'avg':\n",
    "            self.head_feats = 512\n",
    "        \n",
    "        if 'vit' in conf.backbone or 'coat' in conf.backbone: \n",
    "            self.backbone = timm.create_model(\n",
    "                conf.backbone,\n",
    "                pretrained=pretrained,\n",
    "                features_only=False,\n",
    "                in_chans=conf.in_chans,\n",
    "                img_size=conf.image_size\n",
    "            )\n",
    "        else:\n",
    "            self.backbone = timm.create_model(\n",
    "                conf.backbone,\n",
    "                pretrained=pretrained,\n",
    "                features_only=False,\n",
    "                in_chans=conf.in_chans,\n",
    "            )\n",
    "        \n",
    "        if 'efficientnet' in conf.backbone:\n",
    "            in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif 'convnext' in conf.backbone:\n",
    "            in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head = nn.Identity()\n",
    "        elif 'maxvit' in conf.backbone:\n",
    "            in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head = nn.Identity()\n",
    "        elif 'coat' in conf.backbone:\n",
    "            in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head = nn.Identity()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.pooler = self._get_pooling(conf.pooling)\n",
    "\n",
    "        self.lstm_lnfn = nn.LSTM(in_features, 256, num_layers=1, dropout=0., bidirectional=True, batch_first=True)\n",
    "        self.lstm_rnfn = nn.LSTM(in_features, 256, num_layers=1, dropout=0., bidirectional=True, batch_first=True)\n",
    "        self.lstm_scs = nn.LSTM(in_features, 256, num_layers=1, dropout=0., bidirectional=True, batch_first=True)\n",
    "        self.lstm_lss = nn.LSTM(in_features, 256, num_layers=1, dropout=0., bidirectional=True, batch_first=True)\n",
    "        self.lstm_rss = nn.LSTM(in_features, 256, num_layers=1, dropout=0., bidirectional=True, batch_first=True)\n",
    "\n",
    "        if 'attn' in self.head_type:\n",
    "            self.attn_lnfn = Attention(512, conf.n_slices)\n",
    "            self.attn_rnfn = Attention(512, conf.n_slices)\n",
    "            self.attn_scs = Attention(512, conf.n_slices)\n",
    "            self.attn_lss = Attention(512, conf.n_slices)\n",
    "            self.attn_rss = Attention(512, conf.n_slices)\n",
    "\n",
    "        self.head_lnfn = nn.Sequential(\n",
    "            nn.Linear(self.head_feats, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, conf.num_class // 5)\n",
    "        )\n",
    "        self.head_rnfn = nn.Sequential(\n",
    "            nn.Linear(self.head_feats, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, conf.num_class // 5)\n",
    "        )\n",
    "        self.head_scs = nn.Sequential(\n",
    "            nn.Linear(self.head_feats, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, conf.num_class // 5)\n",
    "        )\n",
    "        self.head_lss = nn.Sequential(\n",
    "            nn.Linear(self.head_feats, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, conf.num_class // 5)\n",
    "        )\n",
    "        self.head_rss = nn.Sequential(\n",
    "            nn.Linear(self.head_feats, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, conf.num_class // 5)\n",
    "        )\n",
    "\n",
    "    def _get_pooling(self, pooling_name):\n",
    "        if pooling_name == 'avg':\n",
    "            return nn.AdaptiveAvgPool2d((1))\n",
    "        elif pooling_name == 'max':\n",
    "            return nn.AdaptiveMaxPool2d((1))\n",
    "        elif pooling_name == 'gem':\n",
    "            return GeM()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        bs, slices, img_h, img_w = inputs.shape\n",
    "\n",
    "        inputs = inputs.view(bs * slices, 1, img_h, img_w)\n",
    "\n",
    "        outputs = self.backbone(inputs)\n",
    "        outputs = self.pooler(outputs)\n",
    "        outputs = outputs.view(bs, slices, -1)\n",
    "        \n",
    "        outputs1, _ = self.lstm_lnfn(outputs)\n",
    "        outputs2, _ = self.lstm_rnfn(outputs)\n",
    "        outputs3, _ = self.lstm_scs(outputs)\n",
    "        outputs4, _ = self.lstm_lss(outputs)\n",
    "        outputs5, _ = self.lstm_rss(outputs)\n",
    "\n",
    "        if self.head_type == 'lstm_attn':\n",
    "            outputs1 = self.attn_lnfn(outputs1)\n",
    "            outputs2 = self.attn_rnfn(outputs2)\n",
    "            outputs3 = self.attn_scs(outputs3)\n",
    "            outputs4 = self.attn_lss(outputs4)\n",
    "            outputs5 = self.attn_rss(outputs5)\n",
    "            \n",
    "        elif self.head_type == 'lstm_mean_max':\n",
    "            outputs1 = torch.concat([outputs1.mean(dim=1), outputs1.amax(dim=1)], dim=-1)\n",
    "            outputs2 = torch.concat([outputs2.mean(dim=1), outputs2.amax(dim=1)], dim=-1)\n",
    "            outputs3 = torch.concat([outputs3.mean(dim=1), outputs3.amax(dim=1)], dim=-1)\n",
    "            outputs4 = torch.concat([outputs4.mean(dim=1), outputs4.amax(dim=1)], dim=-1)\n",
    "            outputs5 = torch.concat([outputs5.mean(dim=1), outputs5.amax(dim=1)], dim=-1)\n",
    "            \n",
    "        elif self.head_type == 'avg':\n",
    "            outputs1 = outputs1.contiguous().view(bs * slices, -1)\n",
    "            outputs2 = outputs2.contiguous().view(bs * slices, -1)\n",
    "            outputs3 = outputs3.contiguous().view(bs * slices, -1)\n",
    "            outputs4 = outputs4.contiguous().view(bs * slices, -1)\n",
    "            outputs5 = outputs5.contiguous().view(bs * slices, -1)\n",
    "        \n",
    "        outputs1 = self.head_lnfn(outputs1)\n",
    "        outputs2 = self.head_rnfn(outputs2)\n",
    "        outputs3 = self.head_scs(outputs3)\n",
    "        outputs4 = self.head_lss(outputs4)\n",
    "        outputs5 = self.head_rss(outputs5)\n",
    "        \n",
    "        if self.head_type == 'avg':\n",
    "            outputs1 = outputs1.view(bs, slices, -1).mean(dim=1)\n",
    "            outputs2 = outputs2.view(bs, slices, -1).mean(dim=1)\n",
    "            outputs3 = outputs3.view(bs, slices, -1).mean(dim=1)\n",
    "            outputs4 = outputs4.view(bs, slices, -1).mean(dim=1)\n",
    "            outputs5 = outputs5.view(bs, slices, -1).mean(dim=1)\n",
    "\n",
    "        return torch.concat([outputs1, outputs2, outputs3, outputs4, outputs5], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a587a92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.957378Z",
     "iopub.status.busy": "2024-09-23T15:40:27.957066Z",
     "iopub.status.idle": "2024-09-23T15:40:27.960579Z",
     "shell.execute_reply": "2024-09-23T15:40:27.959743Z"
    },
    "papermill": {
     "duration": 0.016207,
     "end_time": "2024-09-23T15:40:27.962530",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.946323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# conf = CONF()\n",
    "# model = LSDCModel(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e640c1d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:27.983462Z",
     "iopub.status.busy": "2024-09-23T15:40:27.983215Z",
     "iopub.status.idle": "2024-09-23T15:40:27.986799Z",
     "shell.execute_reply": "2024-09-23T15:40:27.985968Z"
    },
    "papermill": {
     "duration": 0.016283,
     "end_time": "2024-09-23T15:40:27.988704",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.972421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# img = torch.rand(2, 25, 128, 128, dtype=torch.float)\n",
    "# outputs = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6595497b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:28.009617Z",
     "iopub.status.busy": "2024-09-23T15:40:28.009007Z",
     "iopub.status.idle": "2024-09-23T15:40:28.012657Z",
     "shell.execute_reply": "2024-09-23T15:40:28.011809Z"
    },
    "papermill": {
     "duration": 0.015808,
     "end_time": "2024-09-23T15:40:28.014471",
     "exception": false,
     "start_time": "2024-09-23T15:40:27.998663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4e0af",
   "metadata": {
    "papermill": {
     "duration": 0.009865,
     "end_time": "2024-09-23T15:40:28.034157",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.024292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Official Metric Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c81a4834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:28.055400Z",
     "iopub.status.busy": "2024-09-23T15:40:28.054760Z",
     "iopub.status.idle": "2024-09-23T15:40:28.070941Z",
     "shell.execute_reply": "2024-09-23T15:40:28.070080Z"
    },
    "papermill": {
     "duration": 0.028886,
     "end_time": "2024-09-23T15:40:28.072926",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.044040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_condition(full_location: str) -> str:\n",
    "    # Given an input like spinal_canal_stenosis_l1_l2 extracts 'spinal'\n",
    "    for injury_condition in ['spinal', 'foraminal', 'subarticular']:\n",
    "        if injury_condition in full_location:\n",
    "            return injury_condition\n",
    "    raise ValueError(f'condition not found in {full_location}')\n",
    "\n",
    "\n",
    "# def score(\n",
    "def calculate_score(\n",
    "        solution: pd.DataFrame,\n",
    "        submission: pd.DataFrame,\n",
    "        evaluate_condition_list: list = ['spinal', 'foraminal', 'subarticular'],\n",
    "        row_id_column_name: str = 'row_id', ### modified: default\n",
    "        any_severe_scalar: float = 1.0, ### modified: added default\n",
    "    ) -> float:\n",
    "    '''\n",
    "    Pseudocode:\n",
    "    1. Calculate the sample weighted log loss for each medical condition:\n",
    "    2. Derive a new any_severe label.\n",
    "    3. Calculate the sample weighted log loss for the new any_severe label.\n",
    "    4. Return the average of all of the label group log losses as the final score, normalized for the number of columns in each group.\n",
    "       This mitigates the impact of spinal stenosis having only half as many columns as the other two conditions.\n",
    "    '''\n",
    "\n",
    "    target_levels = ['normal_mild', 'moderate', 'severe']\n",
    "\n",
    "    # Run basic QC checks on the inputs\n",
    "    if not pandas.api.types.is_numeric_dtype(submission[target_levels].values):\n",
    "        raise ParticipantVisibleError('All submission values must be numeric')\n",
    "\n",
    "    if not np.isfinite(submission[target_levels].values).all():\n",
    "        raise ParticipantVisibleError('All submission values must be finite')\n",
    "\n",
    "    if solution[target_levels].min().min() < 0:\n",
    "        raise ParticipantVisibleError('All labels must be at least zero')\n",
    "    if submission[target_levels].min().min() < 0:\n",
    "        raise ParticipantVisibleError('All predictions must be at least zero')\n",
    "\n",
    "    solution['study_id'] = solution['row_id'].apply(lambda x: x.split('_')[0])\n",
    "    solution['location'] = solution['row_id'].apply(lambda x: '_'.join(x.split('_')[1:]))\n",
    "    solution['condition'] = solution['row_id'].apply(get_condition)\n",
    "\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "    assert sorted(submission.columns) == sorted(target_levels)\n",
    "\n",
    "    submission['study_id'] = solution['study_id']\n",
    "    submission['location'] = solution['location']\n",
    "    submission['condition'] = solution['condition']\n",
    "\n",
    "    condition_losses = []\n",
    "    condition_weights = []\n",
    "\n",
    "#     for condition in ['spinal', 'foraminal', 'subarticular']: ## modified\n",
    "    for condition in evaluate_condition_list:\n",
    "        condition_indices = solution.loc[solution['condition'] == condition].index.values\n",
    "        condition_loss = sklearn.metrics.log_loss(\n",
    "            y_true=solution.loc[condition_indices, target_levels].values,\n",
    "            y_pred=submission.loc[condition_indices, target_levels].values,\n",
    "            sample_weight=solution.loc[condition_indices, 'sample_weight'].values\n",
    "        )\n",
    "        condition_losses.append(condition_loss)\n",
    "        condition_weights.append(1)\n",
    "\n",
    "    any_severe_spinal_labels = pd.Series(solution.loc[solution['condition'] == 'spinal'].groupby('study_id')['severe'].max())\n",
    "    any_severe_spinal_weights = pd.Series(solution.loc[solution['condition'] == 'spinal'].groupby('study_id')['sample_weight'].max())\n",
    "    any_severe_spinal_predictions = pd.Series(submission.loc[submission['condition'] == 'spinal'].groupby('study_id')['severe'].max())\n",
    "\n",
    "    any_severe_spinal_loss = sklearn.metrics.log_loss(\n",
    "        y_true=any_severe_spinal_labels,\n",
    "        y_pred=any_severe_spinal_predictions,\n",
    "        sample_weight=any_severe_spinal_weights,\n",
    "        labels=[0., 1.]  ### modified: make it also run in debug run\n",
    "    )\n",
    "\n",
    "    condition_losses.append(any_severe_spinal_loss)\n",
    "    condition_weights.append(any_severe_scalar)\n",
    "    return np.average(condition_losses, weights=condition_weights), any_severe_spinal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76faf1c7",
   "metadata": {
    "papermill": {
     "duration": 0.009583,
     "end_time": "2024-09-23T15:40:28.092450",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.082867",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c1c1ef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:28.114200Z",
     "iopub.status.busy": "2024-09-23T15:40:28.113460Z",
     "iopub.status.idle": "2024-09-23T15:40:28.119788Z",
     "shell.execute_reply": "2024-09-23T15:40:28.118972Z"
    },
    "papermill": {
     "duration": 0.019101,
     "end_time": "2024-09-23T15:40:28.121701",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.102600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train/notebook\n",
    "class Averager:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "    def get_average(self):\n",
    "        return self.avg\n",
    "    \n",
    "    def get_value(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bec9b1fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:28.142463Z",
     "iopub.status.busy": "2024-09-23T15:40:28.142225Z",
     "iopub.status.idle": "2024-09-23T15:40:28.150479Z",
     "shell.execute_reply": "2024-09-23T15:40:28.149690Z"
    },
    "papermill": {
     "duration": 0.020726,
     "end_time": "2024-09-23T15:40:28.152269",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.131543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimerError(Exception):\n",
    "    \"\"\"A custom exception used to report errors in use of Timer class\"\"\"\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.split_time = []\n",
    "        self._start_time = None\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start a new timer\"\"\"\n",
    "        if self._start_time is not None:\n",
    "            raise TimerError(f\"Timer is running. Use .stop() to stop it\")\n",
    "\n",
    "        self._start_time = time.perf_counter()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer, and report the elapsed time\"\"\"\n",
    "        if self._start_time is None:\n",
    "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
    "            \n",
    "        self._start_time = None\n",
    "    \n",
    "    def get_time(self):\n",
    "        if self._start_time is None:\n",
    "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
    "            \n",
    "        return time.perf_counter() - self._start_time\n",
    "    \n",
    "    def split(self):\n",
    "        if self._start_time is None:\n",
    "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
    "            \n",
    "        self.split_time.append(time.perf_counter() - self._start_time)\n",
    "    \n",
    "    def get_split_time(self, idx):\n",
    "        return self.split_time[idx]\n",
    "    \n",
    "    @staticmethod\n",
    "    def formatting(second):\n",
    "        return str(datetime.timedelta(seconds=round(second)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec64420",
   "metadata": {
    "papermill": {
     "duration": 0.009796,
     "end_time": "2024-09-23T15:40:28.172253",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.162457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d254edf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:28.193678Z",
     "iopub.status.busy": "2024-09-23T15:40:28.193428Z",
     "iopub.status.idle": "2024-09-23T15:40:28.206899Z",
     "shell.execute_reply": "2024-09-23T15:40:28.206089Z"
    },
    "papermill": {
     "duration": 0.026549,
     "end_time": "2024-09-23T15:40:28.208737",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.182188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_preprocess(conf, df_):\n",
    "    print('data preprocessing..')\n",
    "    df = df_.clone()\n",
    "\n",
    "    df = df.with_columns(pl.concat_str([\n",
    "        pl.lit(conf.data_path),\n",
    "        pl.col('study_id'),\n",
    "        pl.col('series_id'),\n",
    "    ], separator='/').alias('series_path'))\n",
    "\n",
    "    slice_samples_stack = {\n",
    "        'series_id': [],\n",
    "        'slices': [],\n",
    "    }\n",
    "\n",
    "    for name, data in df.group_by(['series_path'], maintain_order=True):\n",
    "        plane = data['series_description'][0]\n",
    "        series_path = Path(name[0])\n",
    "        series_id = series_path.name\n",
    "\n",
    "#         dcm_array = np.sort([int(path.stem) for path in series_path.glob('*.dcm')])\n",
    "        dcm_array = np.sort([int(path.stem) for path in series_path.glob('*.npy')])\n",
    "        if plane != 'Axial T2':\n",
    "\n",
    "            series_info = sagittal_IPP.filter(pl.col('series_id') == int(series_id))\n",
    "            mid_idx = dcm_array[len(dcm_array) // 2] # should be fine in most case but may be inaccurate, check later\n",
    "\n",
    "            first = series_info.filter(pl.col('instance_number') == series_info['instance_number'].min())\n",
    "            first_IPP_x = first[\"ImagePositionPatient_x\"].item(0)\n",
    "            first_sl = first[\"SliceLocation\"].item(0)\n",
    "\n",
    "            last = series_info.filter(pl.col('instance_number') == series_info['instance_number'].max())\n",
    "            last_IPP_x = last[\"ImagePositionPatient_x\"].item(0)\n",
    "            last_sl = last[\"SliceLocation\"].item(0)\n",
    "\n",
    "            mid_info = series_info.filter(pl.col('instance_number') == mid_idx)\n",
    "\n",
    "            neutral = series_info['SliceLocation'].to_numpy() - mid_info['SliceLocation'].to_numpy()\n",
    "            side1_idx = np.argmin(np.abs(neutral - conf.spine_side_dist_mm)) + 1\n",
    "            side2_idx = np.argmin(np.abs(neutral + conf.spine_side_dist_mm)) + 1\n",
    "\n",
    "            side1_pack = dcm_array[side1_idx - 2: side1_idx + 1]\n",
    "            mid_pack = dcm_array[mid_idx - 3: mid_idx + 2]\n",
    "            side2_pack = dcm_array[side2_idx - 2: side2_idx + 1]\n",
    "\n",
    "            cond1 = (first_IPP_x > last_IPP_x) and (first_sl > last_sl)\n",
    "            cond2 = (first_IPP_x < last_IPP_x) and (first_sl < last_sl)\n",
    "\n",
    "            if cond1 or cond2:\n",
    "                pack = np.concatenate([side1_pack, mid_pack, side2_pack]) # this pack: less is right, greater is left\n",
    "            else:\n",
    "                pack = np.concatenate([side2_pack, mid_pack, side1_pack]) # this pack: lesser is left, greater is right\n",
    "        else:\n",
    "            pack = dcm_array # only axial t2 take all file name to process later in dataset\n",
    "\n",
    "        slice_samples_stack['series_id'].append(series_id)\n",
    "        slice_samples_stack['slices'].append(pack)\n",
    "\n",
    "    slice_samples_stack = pl.DataFrame(slice_samples_stack).with_columns(pl.col('series_id').cast(pl.Int64))\n",
    "\n",
    "    return df.join(slice_samples_stack, on='series_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4efcee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:28.229938Z",
     "iopub.status.busy": "2024-09-23T15:40:28.229706Z",
     "iopub.status.idle": "2024-09-23T15:40:28.235812Z",
     "shell.execute_reply": "2024-09-23T15:40:28.234967Z"
    },
    "papermill": {
     "duration": 0.018635,
     "end_time": "2024-09-23T15:40:28.237686",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.219051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
    "    # https://github.com/gokulprasadthekkel/pytorch-multi-class-focal-loss/tree/master\n",
    "    def __init__(self, weight=None, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__(weight, reduction=reduction)\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        ce_loss = F.cross_entropy(input, target, reduction=self.reduction, weight=self.weight)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c9c4dcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:28.259667Z",
     "iopub.status.busy": "2024-09-23T15:40:28.259425Z",
     "iopub.status.idle": "2024-09-23T15:40:28.284087Z",
     "shell.execute_reply": "2024-09-23T15:40:28.283290Z"
    },
    "papermill": {
     "duration": 0.038193,
     "end_time": "2024-09-23T15:40:28.286240",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.248047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dcm(path):\n",
    "    dicom = pydicom.dcmread(path)\n",
    "    data = dicom.pixel_array\n",
    "    return data\n",
    "\n",
    "def extract_config(conf_):\n",
    "    config_dict = {}\n",
    "    for k, v in vars(conf_).items():\n",
    "        if not k.startswith('_'):\n",
    "            config_dict[k] = v\n",
    "\n",
    "    with open(Path(conf_.save_path, 'config.yaml'), 'w+') as file:\n",
    "        yaml.dump(config_dict, file)\n",
    "\n",
    "    print('Extracted config')\n",
    "\n",
    "def get_dataloader(conf, df, train_dataset, valid_dataset):\n",
    "\n",
    "    train_dataset = LSDCTrainDataset(conf, df, train_dataset, patient_coords, axial_IPP, get_transforms(conf, types='train'))\n",
    "    valid_dataset = LSDCTrainDataset(conf, df, valid_dataset, patient_coords, axial_IPP, get_transforms(conf, types='valid'))\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=conf.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=conf.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=conf.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=conf.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    return train_dataloader, valid_dataloader\n",
    "\n",
    "def get_model(conf):\n",
    "    model = LSDCModel(conf, pretrained=True)\n",
    "    return model\n",
    "\n",
    "def get_criterion(conf_criterion, class_weight=None):\n",
    "    criterion_dict = {\n",
    "        'ce': nn.CrossEntropyLoss(weight=class_weight),\n",
    "        'bce': nn.BCEWithLogitsLoss(weight=class_weight),\n",
    "        'focal': FocalLoss(weight=class_weight),\n",
    "    }\n",
    "    return criterion_dict[conf_criterion]\n",
    "\n",
    "def get_scheduler(conf, samples_per_epoch):\n",
    "    scheduler_dict = {\n",
    "        'cosine_warmup': {\n",
    "            'scheduler': transformers.get_cosine_schedule_with_warmup,\n",
    "            'hparams': {\n",
    "                'num_warmup_steps': int(samples_per_epoch * conf.num_epochs * conf.warmup_ratios),\n",
    "                'num_training_steps': samples_per_epoch * conf.num_epochs,\n",
    "            }\n",
    "        },\n",
    "        'linear_warmup': {\n",
    "            'scheduler':transformers.get_linear_schedule_with_warmup,\n",
    "            'hparams': {\n",
    "                'num_warmup_steps': int(samples_per_epoch * conf.num_epochs * conf.warmup_ratios),\n",
    "                'num_training_steps': samples_per_epoch * conf.num_epochs,\n",
    "            }\n",
    "        },\n",
    "        'constant_warmup': {\n",
    "            'scheduler':transformers.get_constant_schedule_with_warmup,\n",
    "            'hparams': {\n",
    "                'num_warmup_steps': int(samples_per_epoch * conf.num_epochs * conf.warmup_ratios),\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    return scheduler_dict[conf.scheduler]['scheduler'], scheduler_dict[conf.scheduler]['hparams']\n",
    "\n",
    "def get_optimizer(conf):\n",
    "    optim_dict = {\n",
    "        'adamw': optim.AdamW,\n",
    "    }\n",
    "    return optim_dict[conf.optimizer]\n",
    "\n",
    "def formatting_predictions(oof_: pd.DataFrame):\n",
    "    oof = pl.from_pandas(oof_.copy())\n",
    "    formatted_df = pl.DataFrame()\n",
    "    \n",
    "    oof = (\n",
    "        oof\n",
    "        .melt(id_vars='study_id_level')\n",
    "        .with_columns(pl.col('study_id_level').str.head(-6).alias('study_id'))\n",
    "        .with_columns(pl.col('study_id_level').str.slice(-5).alias('level'))\n",
    "    )\n",
    "\n",
    "    for cond in ['normal_mild', 'moderate', 'severe']:\n",
    "        tmp = (\n",
    "            oof\n",
    "            .filter(pl.col('variable').str.contains(f'{cond}'))\n",
    "            .with_columns(pl.col('variable').str.head(-len(f'_{cond}')).alias('condition'))\n",
    "            .with_columns(pl.concat_str([\n",
    "                pl.col('study_id'),\n",
    "                pl.col('condition'),\n",
    "                pl.col('level'),\n",
    "            ], separator='_').alias('row_id'))\n",
    "            .rename({'value': f'{cond}'})\n",
    "            .select(['row_id', f'{cond}']) # different from others\n",
    "        )\n",
    "        if formatted_df.is_empty():\n",
    "            formatted_df = tmp\n",
    "        else:\n",
    "            formatted_df = formatted_df.join(tmp, on='row_id')\n",
    "    \n",
    "    # for filtering\n",
    "    formatted_df = formatted_df.with_columns(pl.col('row_id').str.split('_').list.first().alias('study_id'))\n",
    "    \n",
    "    return formatted_df.sort('row_id').to_pandas()\n",
    "\n",
    "def mixup(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    idx = torch.randperm(x.size(0))\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[idx]\n",
    "    y_a, y_b = y, y[idx]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def cutmix(data, targets, alpha=1.0):\n",
    "# https://github.com/hysts/pytorch_cutmix/blob/master/cutmix.py\n",
    "    idx = torch.randperm(data.size(0))\n",
    "    image_h, image_w = data.size(-2), data.size(-1)\n",
    "    shuffled_data = data[idx]\n",
    "    shuffled_targets = targets[idx]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "\n",
    "    cx = np.random.uniform(0, image_w)\n",
    "    cy = np.random.uniform(0, image_h)\n",
    "    w = image_w * np.sqrt(1 - lam)\n",
    "    h = image_h * np.sqrt(1 - lam)\n",
    "    x0 = int(np.round(max(cx - w / 2, 0)))\n",
    "    x1 = int(np.round(min(cx + w / 2, image_w)))\n",
    "    y0 = int(np.round(max(cy - h / 2, 0)))\n",
    "    y1 = int(np.round(min(cy + h / 2, image_h)))\n",
    "\n",
    "    data[:, :, y0:y1, x0:x1] = shuffled_data[:, :, y0:y1, x0:x1]\n",
    "\n",
    "    return data, targets, shuffled_targets, lam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88ba01",
   "metadata": {
    "papermill": {
     "duration": 0.010039,
     "end_time": "2024-09-23T15:40:28.306691",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.296652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f3bd549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:28.328847Z",
     "iopub.status.busy": "2024-09-23T15:40:28.328587Z",
     "iopub.status.idle": "2024-09-23T15:40:28.371654Z",
     "shell.execute_reply": "2024-09-23T15:40:28.370877Z"
    },
    "papermill": {
     "duration": 0.05653,
     "end_time": "2024-09-23T15:40:28.373500",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.316970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, debug_run, fold, conf, device, model, optimizer, scheduler, scheduler_hparams, criterion\n",
    "    ):\n",
    "        self.debug_run = debug_run\n",
    "        self.current_fold = fold\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer(model.parameters(), lr=conf.lr, eps=conf.optim_eps, betas=(conf.optim_betas1, conf.optim_betas2))\n",
    "        self.scheduler = scheduler(self.optimizer, **scheduler_hparams)\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.apex = conf.apex\n",
    "        self.scaler = GradScaler(enabled=self.apex)\n",
    "        self.exp_num = conf.exp\n",
    "        self.num_class = conf.num_class\n",
    "        self.num_epochs = conf.num_epochs\n",
    "        self.verbose_step = conf.verbose_step\n",
    "        self.save_path = conf.save_path\n",
    "        self.use_mix = conf.use_mix\n",
    "        self.mix_type = conf.mix_type\n",
    "        self.mix_p = conf.mix_p\n",
    "        self.clip_grad_norm = conf.clip_grad_norm\n",
    "        self.max_grad_norm = conf.max_grad_norm\n",
    "\n",
    "        self.best_score = 100\n",
    "        self.best_valid_loss = 100\n",
    "\n",
    "        self.oof_cols = [ # following alphabet sorting\n",
    "            'study_id_level',\n",
    "            # sagittal_t1\n",
    "            'left_neural_foraminal_narrowing_normal_mild',\n",
    "            'left_neural_foraminal_narrowing_moderate',\n",
    "            'left_neural_foraminal_narrowing_severe',\n",
    "\n",
    "            'right_neural_foraminal_narrowing_normal_mild',\n",
    "            'right_neural_foraminal_narrowing_moderate',\n",
    "            'right_neural_foraminal_narrowing_severe',\n",
    "\n",
    "            # sagittal_t2\n",
    "            'spinal_canal_stenosis_normal_mild',\n",
    "            'spinal_canal_stenosis_moderate',\n",
    "            'spinal_canal_stenosis_severe',\n",
    "\n",
    "            # axial\n",
    "            'left_subarticular_stenosis_normal_mild',\n",
    "            'left_subarticular_stenosis_moderate',\n",
    "            'left_subarticular_stenosis_severe',\n",
    "\n",
    "            'right_subarticular_stenosis_normal_mild',\n",
    "            'right_subarticular_stenosis_moderate',\n",
    "            'right_subarticular_stenosis_severe',\n",
    "        ]\n",
    "\n",
    "        self.oof_df = pd.DataFrame()\n",
    "        self.oof_valid_loss_df = pd.DataFrame()\n",
    "        \n",
    "        self.raw_oof_df = pd.DataFrame()\n",
    "        self.raw_oof_valid_loss_df = pd.DataFrame()\n",
    "\n",
    "        self.record_cols = ['fold', 'epoch', 'train_loss', 'valid_loss', 'score']\n",
    "        self.record = pd.DataFrame(columns=self.record_cols)\n",
    "\n",
    "    def fit(self, train_loader, valid_loader):\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.log(f'exp: {self.exp_num}')\n",
    "        self.log(f'--- FOLD {self.current_fold} ---')\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.current_epoch = epoch\n",
    "\n",
    "            train_loss = self._train_fn(train_loader)\n",
    "\n",
    "            valid_loss, ids_list, labels_list, outputs_list = self._valid_fn(valid_loader)\n",
    "\n",
    "            this_epoch_score = self._eval_fn(ids_list, labels_list, outputs_list, valid_loss)\n",
    "\n",
    "            self.record = pd.concat([\n",
    "                self.record,\n",
    "                pd.DataFrame(dict(zip(self.record_cols, np.array([\n",
    "                    self.current_fold, self.current_epoch, train_loss, valid_loss, this_epoch_score\n",
    "                ]).reshape(-1, 1))))\n",
    "            ], axis=0)\n",
    "\n",
    "            self.log(f'-- [Fold: {self.current_fold}, Epoch: {self.current_epoch + 1}] DONE --\\n')\n",
    "\n",
    "            if self.debug_run: break\n",
    "\n",
    "        return self.record, self.oof_df, self.oof_valid_loss_df, self.raw_oof_df, self.raw_oof_valid_loss_df\n",
    "\n",
    "    def _train_fn(self, train_loader):\n",
    "        self.log('TRAINL_LOOP')\n",
    "        self.model.train()\n",
    "        total_loss = Averager()\n",
    "        current_lr = self.scheduler.get_lr()[0]\n",
    "        timer = Timer()\n",
    "        timer.start()\n",
    "\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            \n",
    "            inputs = batch['images'].to(self.device, dtype=torch.float)\n",
    "            labels = batch['labels'].to(self.device, dtype=torch.float)\n",
    "            batchsize = labels.shape[0]\n",
    "\n",
    "            if self.use_mix:\n",
    "                is_mix_applied = False\n",
    "                if random.random() > self.mix_p:\n",
    "                    is_mix_applied = True\n",
    "                    if self.mix_type == 'mixup':\n",
    "                        inputs, labels, labels_mixed, lam = mixup(inputs, labels)\n",
    "                    elif self.mix_type == 'cutmix':\n",
    "                        inputs, labels, labels_mixed, lam = cutmix(inputs, labels)\n",
    "                    else:\n",
    "                        raise NotImplementedError\n",
    "\n",
    "            with autocast(enabled=self.apex):\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                loss = 0\n",
    "                for c in range(0, self.num_class, 3):\n",
    "                    loss += self.criterion(outputs[:, c: c + 3], labels[:, c: c + 3])\n",
    "                loss /= (self.num_class // 3)\n",
    "                \n",
    "                if self.use_mix and is_mix_applied:\n",
    "                    loss_mixed = 0\n",
    "                    for c in range(0, self.num_class, 3):\n",
    "                        loss_mixed += self.criterion(outputs[:, c: c + 3], labels_mixed[:, c: c + 3])\n",
    "                    loss_mixed /= (self.num_class // 3)\n",
    "                    loss = (loss * lam)  + (loss_mixed * (1 - lam))\n",
    "\n",
    "            total_loss.update(loss.item(), batchsize)\n",
    "\n",
    "            current_lr = self.scheduler.get_lr()[0]\n",
    "\n",
    "            self.scaler.scale(loss).backward()\n",
    "            if self.clip_grad_norm:\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                grad_norm = nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "\n",
    "            self.scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            if step % self.verbose_step == 0 or step == (len(train_loader) - 1):\n",
    "                self.log(\n",
    "                    f'[TRAIN_F{self.current_fold}], ' + \\\n",
    "                    f'E: {self.current_epoch + 1}/{self.num_epochs}, ' + \\\n",
    "                    f'S: {str(step).zfill(len(str(len(train_loader))))}/{len(train_loader)}, ' + \\\n",
    "                    f'L: {total_loss.get_average():.5f}, ' + \\\n",
    "                    f'LR: {current_lr:.8f}, ' + \\\n",
    "                    f'T: {Timer.formatting(timer.get_time())}'\n",
    "                )\n",
    "\n",
    "            if self.debug_run: break\n",
    "            # end of train loop\n",
    "        timer.stop()\n",
    "\n",
    "        return total_loss.get_average()\n",
    "\n",
    "    def _valid_fn(self, valid_loader):\n",
    "        self.log(\"\\nVALID_LOOP\")\n",
    "        self.model.eval()\n",
    "\n",
    "        ids_list = []\n",
    "        outputs_list = []\n",
    "        labels_list = []\n",
    "\n",
    "        total_loss = Averager()\n",
    "        timer = Timer()\n",
    "        timer.start()\n",
    "\n",
    "        for step, batch in enumerate(valid_loader):\n",
    "\n",
    "            ids = batch['study_id_level']\n",
    "            inputs = batch['images'].to(self.device, dtype=torch.float)\n",
    "            labels = batch['labels'].to(self.device, dtype=torch.float)\n",
    "            batchsize = labels.shape[0]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                loss = 0\n",
    "                for c in range(0, self.num_class, 3):\n",
    "                    loss += self.criterion(outputs[:, c: c + 3], labels[:, c: c + 3])\n",
    "                loss /= (self.num_class // 3)\n",
    "\n",
    "            total_loss.update(loss.item(), batchsize)\n",
    "\n",
    "            ids_list.extend(ids)\n",
    "            labels_list.append(labels)\n",
    "            outputs_list.append(outputs)\n",
    "\n",
    "            if step % self.verbose_step == 0 or step == (len(valid_loader) - 1):\n",
    "                self.log(\n",
    "                    f'[VALID_F{self.current_fold}], ' + \\\n",
    "                    f'E: {self.current_epoch + 1}/{self.num_epochs}, ' + \\\n",
    "                    f'S: {str(step).zfill(len(str(len(valid_loader))))}/{len(valid_loader)}, ' + \\\n",
    "                    f'L: {total_loss.get_average():.5f}, ' + \\\n",
    "                    f'T: {Timer.formatting(timer.get_time())}'\n",
    "                )\n",
    "            if self.debug_run: break\n",
    "            # end of the valid loop\n",
    "\n",
    "        labels_list = torch.concat(labels_list).cpu()\n",
    "        outputs_list = torch.concat(outputs_list).cpu()\n",
    "\n",
    "        return total_loss.get_average(), ids_list, labels_list, outputs_list\n",
    "\n",
    "    def _eval_fn(self, ids_list, y_trues, y_preds, valid_loss):\n",
    "        batchsize = len(y_trues)\n",
    "        score = 0\n",
    "        \n",
    "        this_raw_oof_df = pd.DataFrame(\n",
    "                {self.oof_cols[0]: ids_list} | dict(zip(self.oof_cols[1:], y_preds.T))\n",
    "            )\n",
    "\n",
    "        for c in range(0, self.num_class, 3):\n",
    "            y_preds[:, c: c + 3] = y_preds[:, c: c + 3].softmax(1)\n",
    "\n",
    "        this_oof_df = pd.DataFrame(\n",
    "                {self.oof_cols[0]: ids_list} | dict(zip(self.oof_cols[1:], y_preds.T))\n",
    "            )\n",
    "        this_oof_df_formatted = formatting_predictions(this_oof_df).drop('study_id', axis=1)\n",
    "        this_solution_df = solution_df[solution_df['row_id'].isin(this_oof_df_formatted['row_id'])].reset_index(drop=True)\n",
    "\n",
    "        check_condition_list = ['spinal', 'foraminal', 'subarticular']\n",
    "\n",
    "        score, any_severe = calculate_score(\n",
    "            this_solution_df.copy(),\n",
    "            this_oof_df_formatted.copy(),\n",
    "            check_condition_list,\n",
    "        )\n",
    "\n",
    "        self.log(f'\\nscore: {score}')\n",
    "        self.log(f'any_severe: {any_severe}')\n",
    "        for indiv_cond in check_condition_list:\n",
    "            indiv_score = calculate_score(\n",
    "                this_solution_df.copy(),\n",
    "                this_oof_df_formatted.copy(),\n",
    "                [indiv_cond],\n",
    "            )[0]\n",
    "            self.log(f'{indiv_cond}: {indiv_score}')\n",
    "\n",
    "        if self.best_score > score :\n",
    "            self.best_score = score\n",
    "            \n",
    "            self.raw_oof_df = this_raw_oof_df\n",
    "            self.oof_df = this_oof_df\n",
    "\n",
    "            file_name = f'best_score_fold{self.current_fold}.pt'\n",
    "\n",
    "            self.model.eval()\n",
    "            torch.save({\n",
    "                'model_state_dict': self.model.state_dict(),\n",
    "                'exp': self.exp_num,\n",
    "                'fold': self.current_fold,\n",
    "                'epoch': self.current_epoch,\n",
    "            }, Path(self.save_path, file_name))\n",
    "\n",
    "            self.log(f'\\n-> [SAVED] Fold: {self.current_fold}, Epoch: {self.current_epoch + 1}, score: {self.best_score}\\n')\n",
    "\n",
    "        if self.best_valid_loss > valid_loss:\n",
    "            self.best_valid_loss = valid_loss\n",
    "\n",
    "            self.raw_oof_valid_loss_df = this_raw_oof_df\n",
    "            self.oof_valid_loss_df = this_oof_df\n",
    "\n",
    "            file_name = f'best_loss_fold{self.current_fold}.pt'\n",
    "\n",
    "            self.model.eval()\n",
    "            torch.save({\n",
    "                'model_state_dict': self.model.state_dict(),\n",
    "                'exp': self.exp_num,\n",
    "                'fold': self.current_fold,\n",
    "                'epoch': self.current_epoch,\n",
    "            }, Path(self.save_path, file_name))\n",
    "\n",
    "            self.log(f'\\n-> [SAVED] Fold: {self.current_fold}, Epoch: {self.current_epoch + 1}, valid_loss: {self.best_valid_loss}\\n')\n",
    "\n",
    "        return score\n",
    "\n",
    "    def log(self, msg):\n",
    "        print(msg)\n",
    "        if not self.debug_run:\n",
    "            with open(Path(self.save_path, 'train.log'), mode='a+', encoding='utf-8') as log:\n",
    "                log.write(f'{msg}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1078312d",
   "metadata": {
    "papermill": {
     "duration": 0.010164,
     "end_time": "2024-09-23T15:40:28.394040",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.383876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c67f28a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:28.415826Z",
     "iopub.status.busy": "2024-09-23T15:40:28.415570Z",
     "iopub.status.idle": "2024-09-23T15:40:28.423498Z",
     "shell.execute_reply": "2024-09-23T15:40:28.422496Z"
    },
    "papermill": {
     "duration": 0.02109,
     "end_time": "2024-09-23T15:40:28.425451",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.404361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CONF:\n",
    "    exp = 'exp164'\n",
    "\n",
    "    data_path = '/kaggle/input/rsna24-lsdc-npy/train_images'\n",
    "    save_path = '/kaggle/working/'\n",
    "    seed = 42\n",
    "\n",
    "    backbone = 'tf_efficientnetv2_s.in21k_ft_in1k'\n",
    "    # 'tf_efficientnetv2_s.in21k_ft_in1k' *\n",
    "\n",
    "    # 'convnext_tiny.in12k_ft_in1k'\n",
    "    # 'convnextv2_tiny.fcmae_ft_in22k_in1k'\n",
    "    # 'convnextv2_nano.fcmae_ft_in22k_in1k'\n",
    "    # 'convnextv2_pico.fcmae_ft_in1k'\n",
    "    \n",
    "    # 'coatnet_1_rw_224.sw_in1k'\n",
    "    # 'coatnet_0_rw_224.sw_in1k'\n",
    "    # 'coatnet_nano_rw_224.sw_in1k'\n",
    "\n",
    "    # 'maxvit_nano_rw_256.sw_in1k'\n",
    "    # 'maxvit_tiny_tf_224.in1k'\n",
    "    # 'maxvit_tiny_tf_384.in1k'\n",
    "    # 'maxvit_tiny_tf_512.in1k'\n",
    "\n",
    "\n",
    "    pooling = 'avg' # ['avg', 'max', 'gem']\n",
    "    head_type = 'lstm_attn' #['lstm_attn', 'lstm_mean_max', 'avg']\n",
    "    \n",
    "    fold_num = 4\n",
    "    train_fold_list = [0, 1, 2, 3]\n",
    "\n",
    "    sagittal_window_ratio = 0.12\n",
    "    \n",
    "    spine_side_dist_mm = 17\n",
    "\n",
    "#     axial_center_crop_size = 224\n",
    "    axial_window_ratio = 0.35\n",
    "    axial_min_dist_threshold = None\n",
    "\n",
    "    num_class = 15\n",
    "    in_chans = 1\n",
    "    n_slices = 25 # (11 + 11) + 3\n",
    "    image_size = 128\n",
    "    \n",
    "    use_mix = False\n",
    "    mix_type = 'mixup' # ['mixup', 'cutmix']\n",
    "    mix_p = 0.5\n",
    "\n",
    "    apex = True\n",
    "    \n",
    "    clip_grad_norm  = False\n",
    "    max_grad_norm = 1.0\n",
    "\n",
    "    criterion = 'ce'\n",
    "\n",
    "    optimizer = 'adamw'\n",
    "    lr = 4e-4\n",
    "    optim_eps = 1e-6\n",
    "    optim_betas1 = 0.9\n",
    "    optim_betas2 = 0.999\n",
    "    scheduler = 'cosine_warmup'\n",
    "    num_epochs = 10\n",
    "    warmup_ratios = 0.2\n",
    "\n",
    "    batch_size = 8\n",
    "    num_workers = 0\n",
    "    verbose_step = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f880ba8c",
   "metadata": {
    "papermill": {
     "duration": 0.009943,
     "end_time": "2024-09-23T15:40:28.445707",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.435764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08b48424",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:28.467677Z",
     "iopub.status.busy": "2024-09-23T15:40:28.467101Z",
     "iopub.status.idle": "2024-09-23T15:40:28.969633Z",
     "shell.execute_reply": "2024-09-23T15:40:28.968720Z"
    },
    "papermill": {
     "duration": 0.51557,
     "end_time": "2024-09-23T15:40:28.971700",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.456130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (44_728, 28)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>study_id</th><th>series_id</th><th>instance_number</th><th>series_description</th><th>condition</th><th>labels</th><th>level</th><th>x</th><th>y</th><th>name</th><th>study_id_level</th><th>fold</th><th>left_neural_foraminal_narrowing_normal_mild</th><th>left_neural_foraminal_narrowing_moderate</th><th>left_neural_foraminal_narrowing_severe</th><th>right_neural_foraminal_narrowing_normal_mild</th><th>right_neural_foraminal_narrowing_moderate</th><th>right_neural_foraminal_narrowing_severe</th><th>spinal_canal_stenosis_normal_mild</th><th>spinal_canal_stenosis_moderate</th><th>spinal_canal_stenosis_severe</th><th>left_subarticular_stenosis_normal_mild</th><th>left_subarticular_stenosis_moderate</th><th>left_subarticular_stenosis_severe</th><th>right_subarticular_stenosis_normal_mild</th><th>right_subarticular_stenosis_moderate</th><th>right_subarticular_stenosis_severe</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;100206310_left_neural_foramina</td><td>100206310</td><td>2092806862</td><td>13</td><td>&quot;Sagittal T1&quot;</td><td>&quot;left_neural_foraminal_narrowin</td><td>0</td><td>&quot;l1_l2&quot;</td><td>270.34225</td><td>148.221459</td><td>&quot;100206310_2092806862_0013&quot;</td><td>&quot;100206310_l1_l2&quot;</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>&quot;100206310_left_neural_foramina</td><td>100206310</td><td>2092806862</td><td>12</td><td>&quot;Sagittal T1&quot;</td><td>&quot;left_neural_foraminal_narrowin</td><td>1</td><td>&quot;l2_l3&quot;</td><td>260.177602</td><td>191.705532</td><td>&quot;100206310_2092806862_0012&quot;</td><td>&quot;100206310_l2_l3&quot;</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>&quot;100206310_left_neural_foramina</td><td>100206310</td><td>2092806862</td><td>13</td><td>&quot;Sagittal T1&quot;</td><td>&quot;left_neural_foraminal_narrowin</td><td>1</td><td>&quot;l3_l4&quot;</td><td>250.176889</td><td>234.398551</td><td>&quot;100206310_2092806862_0013&quot;</td><td>&quot;100206310_l3_l4&quot;</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td></tr><tr><td>&quot;100206310_left_neural_foramina</td><td>100206310</td><td>2092806862</td><td>12</td><td>&quot;Sagittal T1&quot;</td><td>&quot;left_neural_foraminal_narrowin</td><td>2</td><td>&quot;l4_l5&quot;</td><td>249.241774</td><td>274.786914</td><td>&quot;100206310_2092806862_0012&quot;</td><td>&quot;100206310_l4_l5&quot;</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td></tr><tr><td>&quot;100206310_left_neural_foramina</td><td>100206310</td><td>2092806862</td><td>12</td><td>&quot;Sagittal T1&quot;</td><td>&quot;left_neural_foraminal_narrowin</td><td>1</td><td>&quot;l5_s1&quot;</td><td>258.80649</td><td>319.853318</td><td>&quot;100206310_2092806862_0012&quot;</td><td>&quot;100206310_l5_s1&quot;</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;992674144_spinal_canal_stenosi</td><td>992674144</td><td>1576603050</td><td>9</td><td>&quot;Sagittal T2/STIR&quot;</td><td>&quot;spinal_canal_stenosis&quot;</td><td>6</td><td>&quot;l1_l2&quot;</td><td>190.682111</td><td>92.252252</td><td>&quot;992674144_1576603050_0009&quot;</td><td>&quot;992674144_l1_l2&quot;</td><td>2</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>&quot;992674144_spinal_canal_stenosi</td><td>992674144</td><td>1576603050</td><td>9</td><td>&quot;Sagittal T2/STIR&quot;</td><td>&quot;spinal_canal_stenosis&quot;</td><td>6</td><td>&quot;l2_l3&quot;</td><td>182.033462</td><td>123.552124</td><td>&quot;992674144_1576603050_0009&quot;</td><td>&quot;992674144_l2_l3&quot;</td><td>2</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>&quot;992674144_spinal_canal_stenosi</td><td>992674144</td><td>1576603050</td><td>9</td><td>&quot;Sagittal T2/STIR&quot;</td><td>&quot;spinal_canal_stenosis&quot;</td><td>6</td><td>&quot;l3_l4&quot;</td><td>175.855856</td><td>162.265122</td><td>&quot;992674144_1576603050_0009&quot;</td><td>&quot;992674144_l3_l4&quot;</td><td>2</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>&quot;992674144_spinal_canal_stenosi</td><td>992674144</td><td>1576603050</td><td>9</td><td>&quot;Sagittal T2/STIR&quot;</td><td>&quot;spinal_canal_stenosis&quot;</td><td>6</td><td>&quot;l4_l5&quot;</td><td>175.032175</td><td>193.976834</td><td>&quot;992674144_1576603050_0009&quot;</td><td>&quot;992674144_l4_l5&quot;</td><td>2</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>&quot;992674144_spinal_canal_stenosi</td><td>992674144</td><td>1576603050</td><td>9</td><td>&quot;Sagittal T2/STIR&quot;</td><td>&quot;spinal_canal_stenosis&quot;</td><td>6</td><td>&quot;l5_s1&quot;</td><td>179.150579</td><td>224.041184</td><td>&quot;992674144_1576603050_0009&quot;</td><td>&quot;992674144_l5_s1&quot;</td><td>2</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (44_728, 28)\n",
       "\n",
       " row_id     study_id   series_id  instance_    left_suba  right_sub  right_sub  right_su \n",
       " ---        ---        ---        number        rticular_  articular  articular  barticul \n",
       " str        i64        i64        ---           stenosis_  _stenosis  _stenosis  ar_steno \n",
       "                                  i64           sev       _no       _mo       sis_se  \n",
       "                                                ---        ---        ---        ---      \n",
       "                                                i64        i64        i64        i64      \n",
       "\n",
       " 100206310  100206310  209280686  13           0          1          0          0        \n",
       " _left_neu             2                                                                  \n",
       " ral_foram                                                                                \n",
       " ina                                                                                     \n",
       " 100206310  100206310  209280686  12           0          1          0          0        \n",
       " _left_neu             2                                                                  \n",
       " ral_foram                                                                                \n",
       " ina                                                                                     \n",
       " 100206310  100206310  209280686  13           0          0          1          0        \n",
       " _left_neu             2                                                                  \n",
       " ral_foram                                                                                \n",
       " ina                                                                                     \n",
       " 100206310  100206310  209280686  12           1          0          1          0        \n",
       " _left_neu             2                                                                  \n",
       " ral_foram                                                                                \n",
       " ina                                                                                     \n",
       " 100206310  100206310  209280686  12           0          0          1          0        \n",
       " _left_neu             2                                                                  \n",
       " ral_foram                                                                                \n",
       " ina                                                                                     \n",
       "                                                                                 \n",
       " 992674144  992674144  157660305  9            0          1          0          0        \n",
       " _spinal_c             0                                                                  \n",
       " anal_sten                                                                                \n",
       " osi                                                                                     \n",
       " 992674144  992674144  157660305  9            0          1          0          0        \n",
       " _spinal_c             0                                                                  \n",
       " anal_sten                                                                                \n",
       " osi                                                                                     \n",
       " 992674144  992674144  157660305  9            0          1          0          0        \n",
       " _spinal_c             0                                                                  \n",
       " anal_sten                                                                                \n",
       " osi                                                                                     \n",
       " 992674144  992674144  157660305  9            0          1          0          0        \n",
       " _spinal_c             0                                                                  \n",
       " anal_sten                                                                                \n",
       " osi                                                                                     \n",
       " 992674144  992674144  157660305  9            0          1          0          0        \n",
       " _spinal_c             0                                                                  \n",
       " anal_sten                                                                                \n",
       " osi                                                                                     \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = '/kaggle/input/rsna24-lsdc-create-dataset/'\n",
    "\n",
    "train_df = pl.read_csv(path + 'merged_train.csv')\n",
    "labels_df = pl.read_csv(path + 'study_id_level_labels.csv')\n",
    "\n",
    "solution_df = pd.read_csv(path + 'solution_df.csv')\n",
    "\n",
    "patient_coords = pl.read_parquet(path + 'patient_coords.parquet')\n",
    "axial_IPP = pl.read_parquet(path + 'axial_img_pos.parquet')\n",
    "sagittal_IPP = pl.read_parquet(path + 'sagittal_img_pos.parquet')\n",
    "\n",
    "train_df = train_df.join(labels_df, on='study_id_level')\n",
    "\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432f8014",
   "metadata": {
    "papermill": {
     "duration": 0.010577,
     "end_time": "2024-09-23T15:40:28.993556",
     "exception": false,
     "start_time": "2024-09-23T15:40:28.982979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb9e6c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:29.016691Z",
     "iopub.status.busy": "2024-09-23T15:40:29.016398Z",
     "iopub.status.idle": "2024-09-23T15:40:29.033075Z",
     "shell.execute_reply": "2024-09-23T15:40:29.032245Z"
    },
    "papermill": {
     "duration": 0.030572,
     "end_time": "2024-09-23T15:40:29.034894",
     "exception": false,
     "start_time": "2024-09-23T15:40:29.004322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(conf, df, debug_run=True):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    class_weight = None # for balancing imbalance dataset\n",
    "    seed_everything(seed=conf.seed)\n",
    "\n",
    "    cv_record = pd.DataFrame()\n",
    "    oof_df = pd.DataFrame()\n",
    "    oof_valid_loss_df = pd.DataFrame()\n",
    "    \n",
    "    raw_oof_df = pd.DataFrame()\n",
    "    raw_oof_valid_loss_df = pd.DataFrame()\n",
    "\n",
    "    extract_config(conf)\n",
    "\n",
    "    if debug_run:\n",
    "        print('DEBUG_RUN')\n",
    "        debug_samples = df.sample(n=8, seed=0).select('study_id')\n",
    "        df = data_preprocess(conf, df.filter(pl.col('study_id').is_in(debug_samples)))\n",
    "        conf.batch_size = 8\n",
    "        conf.train_fold_list = [0]\n",
    "    else:\n",
    "        df = data_preprocess(conf, df)\n",
    "        \n",
    "#     df = split_fold(conf, df) # already split\n",
    "\n",
    "    for fold in conf.train_fold_list:\n",
    "        seed_everything(conf.seed)\n",
    "        model = get_model(conf)\n",
    "\n",
    "        train_dataset = df.filter(pl.col('fold') != fold)['study_id_level'].unique(maintain_order=True)\n",
    "        valid_dataset = df.filter(pl.col('fold') == fold)['study_id_level'].unique(maintain_order=True)\n",
    "\n",
    "        train_loader, valid_loader = get_dataloader(conf, df, train_dataset, valid_dataset)\n",
    "        optimizer = get_optimizer(conf)\n",
    "        scheduler, scheduler_hparams = get_scheduler(conf, len(train_loader))\n",
    "        criterion = get_criterion(conf.criterion, class_weight)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            debug_run, fold, conf, device, model, optimizer, scheduler, scheduler_hparams, criterion,\n",
    "        )\n",
    "        fold_record, fold_oof, fold_oof_valid_loss, fold_raw_oof, fold_raw_oof_valid_loss = trainer.fit(train_loader, valid_loader)\n",
    "\n",
    "        oof_df = pd.concat([oof_df, fold_oof], axis=0)\n",
    "        oof_valid_loss_df = pd.concat([oof_valid_loss_df, fold_oof_valid_loss], axis=0)\n",
    "\n",
    "        raw_oof_df = pd.concat([raw_oof_df, fold_raw_oof], axis=0)\n",
    "        raw_oof_valid_loss_df = pd.concat([raw_oof_valid_loss_df, fold_raw_oof_valid_loss], axis=0)\n",
    "        \n",
    "        cv_record = pd.concat([cv_record, fold_record], axis=0).reset_index(drop=True)\n",
    "\n",
    "        if debug_run: break\n",
    "\n",
    "    best_epoch_idx = [cv_record[cv_record['fold'] == i]['score'].idxmin() for i in conf.train_fold_list]\n",
    "    best_epoch_record  = cv_record[cv_record.index.isin(best_epoch_idx)].reset_index(drop=True)\n",
    "\n",
    "    cv_record[['fold', 'epoch']] = cv_record[['fold', 'epoch']].astype(int)\n",
    "    best_epoch_record[['fold', 'epoch']] = best_epoch_record[['fold', 'epoch']].astype(int)\n",
    "\n",
    "    display(cv_record)\n",
    "    display(best_epoch_record)\n",
    "\n",
    "    oof_df.to_csv(Path(conf.save_path, 'oof_df.csv'), index=False)\n",
    "    oof_valid_loss_df.to_csv(Path(conf.save_path, 'oof_valid_loss_df.csv'), index=False)\n",
    "    raw_oof_df.to_csv(Path(conf.save_path, 'raw_oof_df.csv'), index=False)\n",
    "    raw_oof_valid_loss_df.to_csv(Path(conf.save_path, 'raw_oof_valid_loss_df.csv'), index=False)\n",
    "    cv_record.to_csv(Path(conf.save_path, 'cv_record.csv'), index=False)\n",
    "    best_epoch_record.to_csv(Path(conf.save_path, 'best_epoch_record.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb2e2667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:40:29.058092Z",
     "iopub.status.busy": "2024-09-23T15:40:29.057816Z",
     "iopub.status.idle": "2024-09-24T00:52:17.773004Z",
     "shell.execute_reply": "2024-09-24T00:52:17.772016Z"
    },
    "papermill": {
     "duration": 33108.730128,
     "end_time": "2024-09-24T00:52:17.776070",
     "exception": false,
     "start_time": "2024-09-23T15:40:29.045942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted config\n",
      "data preprocessing..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6639da688747a99f4af8e657f960c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/86.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp: exp164\n",
      "--- FOLD 0 ---\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F0], E: 1/10, S: 000/840, L: 1.14990, LR: 0.00000000, T: 0:00:04\n",
      "[TRAIN_F0], E: 1/10, S: 200/840, L: 1.04115, LR: 0.00004762, T: 0:06:34\n",
      "[TRAIN_F0], E: 1/10, S: 400/840, L: 0.87740, LR: 0.00009524, T: 0:10:50\n",
      "[TRAIN_F0], E: 1/10, S: 600/840, L: 0.77560, LR: 0.00014286, T: 0:14:22\n",
      "[TRAIN_F0], E: 1/10, S: 800/840, L: 0.71871, LR: 0.00019048, T: 0:17:54\n",
      "[TRAIN_F0], E: 1/10, S: 839/840, L: 0.70780, LR: 0.00019976, T: 0:18:35\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F0], E: 1/10, S: 000/279, L: 0.44782, T: 0:00:01\n",
      "[VALID_F0], E: 1/10, S: 200/279, L: 0.41154, T: 0:02:58\n",
      "[VALID_F0], E: 1/10, S: 278/279, L: 0.41790, T: 0:04:09\n",
      "\n",
      "score: 0.5957185865725956\n",
      "any_severe: 0.5506159415968659\n",
      "spinal: 0.4826597098266733\n",
      "foraminal: 0.6250869118275185\n",
      "subarticular: 0.6343064930878652\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 1, score: 0.5957185865725956\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 1, valid_loss: 0.417896091897926\n",
      "\n",
      "-- [Fold: 0, Epoch: 1] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F0], E: 2/10, S: 000/840, L: 0.55753, LR: 0.00020000, T: 0:00:01\n",
      "[TRAIN_F0], E: 2/10, S: 200/840, L: 0.50717, LR: 0.00024762, T: 0:02:50\n",
      "[TRAIN_F0], E: 2/10, S: 400/840, L: 0.50419, LR: 0.00029524, T: 0:05:39\n",
      "[TRAIN_F0], E: 2/10, S: 600/840, L: 0.50271, LR: 0.00034286, T: 0:08:27\n",
      "[TRAIN_F0], E: 2/10, S: 800/840, L: 0.49988, LR: 0.00039048, T: 0:11:17\n",
      "[TRAIN_F0], E: 2/10, S: 839/840, L: 0.49784, LR: 0.00039976, T: 0:11:51\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F0], E: 2/10, S: 000/279, L: 0.38359, T: 0:00:00\n",
      "[VALID_F0], E: 2/10, S: 200/279, L: 0.38159, T: 0:01:21\n",
      "[VALID_F0], E: 2/10, S: 278/279, L: 0.38694, T: 0:01:52\n",
      "\n",
      "score: 0.4698372203152193\n",
      "any_severe: 0.3343839256429722\n",
      "spinal: 0.32516911151489447\n",
      "foraminal: 0.45626320556520394\n",
      "subarticular: 0.49262604919331254\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 2, score: 0.4698372203152193\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 2, valid_loss: 0.38694456467246263\n",
      "\n",
      "-- [Fold: 0, Epoch: 2] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F0], E: 3/10, S: 000/840, L: 0.41883, LR: 0.00040000, T: 0:00:01\n",
      "[TRAIN_F0], E: 3/10, S: 200/840, L: 0.50575, LR: 0.00039913, T: 0:02:48\n",
      "[TRAIN_F0], E: 3/10, S: 400/840, L: 0.51133, LR: 0.00039651, T: 0:05:38\n",
      "[TRAIN_F0], E: 3/10, S: 600/840, L: 0.49781, LR: 0.00039218, T: 0:08:29\n",
      "[TRAIN_F0], E: 3/10, S: 800/840, L: 0.49202, LR: 0.00038617, T: 0:11:19\n",
      "[TRAIN_F0], E: 3/10, S: 839/840, L: 0.48984, LR: 0.00038481, T: 0:11:53\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F0], E: 3/10, S: 000/279, L: 0.36180, T: 0:00:00\n",
      "[VALID_F0], E: 3/10, S: 200/279, L: 0.37656, T: 0:01:28\n",
      "[VALID_F0], E: 3/10, S: 278/279, L: 0.38044, T: 0:02:01\n",
      "\n",
      "score: 0.4697654645019914\n",
      "any_severe: 0.3640950008435318\n",
      "spinal: 0.33957012290084765\n",
      "foraminal: 0.4549609017973638\n",
      "subarticular: 0.5090949051493032\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 3, score: 0.4697654645019914\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 3, valid_loss: 0.3804424738536501\n",
      "\n",
      "-- [Fold: 0, Epoch: 3] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F0], E: 4/10, S: 000/840, L: 0.15455, LR: 0.00038478, T: 0:00:01\n",
      "[TRAIN_F0], E: 4/10, S: 200/840, L: 0.47938, LR: 0.00037682, T: 0:02:51\n",
      "[TRAIN_F0], E: 4/10, S: 400/840, L: 0.47564, LR: 0.00036733, T: 0:05:44\n",
      "[TRAIN_F0], E: 4/10, S: 600/840, L: 0.46745, LR: 0.00035637, T: 0:08:35\n",
      "[TRAIN_F0], E: 4/10, S: 800/840, L: 0.45952, LR: 0.00034404, T: 0:11:27\n",
      "[TRAIN_F0], E: 4/10, S: 839/840, L: 0.45986, LR: 0.00034149, T: 0:12:00\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F0], E: 4/10, S: 000/279, L: 0.39311, T: 0:00:00\n",
      "[VALID_F0], E: 4/10, S: 200/279, L: 0.35661, T: 0:01:29\n",
      "[VALID_F0], E: 4/10, S: 278/279, L: 0.36241, T: 0:02:05\n",
      "\n",
      "score: 0.4594554243939647\n",
      "any_severe: 0.3094748710132458\n",
      "spinal: 0.31128515589194783\n",
      "foraminal: 0.4306883142760025\n",
      "subarticular: 0.4864122496332249\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 4, score: 0.4594554243939647\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 4, valid_loss: 0.36241112686192506\n",
      "\n",
      "-- [Fold: 0, Epoch: 4] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F0], E: 5/10, S: 000/840, L: 0.81828, LR: 0.00034142, T: 0:00:01\n",
      "[TRAIN_F0], E: 5/10, S: 200/840, L: 0.43891, LR: 0.00032760, T: 0:02:50\n",
      "[TRAIN_F0], E: 5/10, S: 400/840, L: 0.44848, LR: 0.00031266, T: 0:05:41\n",
      "[TRAIN_F0], E: 5/10, S: 600/840, L: 0.44433, LR: 0.00029674, T: 0:08:32\n",
      "[TRAIN_F0], E: 5/10, S: 800/840, L: 0.44244, LR: 0.00027998, T: 0:11:22\n",
      "[TRAIN_F0], E: 5/10, S: 839/840, L: 0.44406, LR: 0.00027662, T: 0:11:55\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F0], E: 5/10, S: 000/279, L: 0.36175, T: 0:00:00\n",
      "[VALID_F0], E: 5/10, S: 200/279, L: 0.36808, T: 0:01:21\n",
      "[VALID_F0], E: 5/10, S: 278/279, L: 0.37369, T: 0:01:50\n",
      "\n",
      "score: 0.5121056480252029\n",
      "any_severe: 0.3248983742541292\n",
      "spinal: 0.3176498163181944\n",
      "foraminal: 0.48404840032760443\n",
      "subarticular: 0.5474114536587361\n",
      "-- [Fold: 0, Epoch: 5] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F0], E: 6/10, S: 000/840, L: 0.48964, LR: 0.00027654, T: 0:00:01\n",
      "[TRAIN_F0], E: 6/10, S: 200/840, L: 0.44994, LR: 0.00025895, T: 0:02:48\n",
      "[TRAIN_F0], E: 6/10, S: 400/840, L: 0.43613, LR: 0.00024085, T: 0:05:36\n",
      "[TRAIN_F0], E: 6/10, S: 600/840, L: 0.43537, LR: 0.00022239, T: 0:08:24\n",
      "[TRAIN_F0], E: 6/10, S: 800/840, L: 0.43461, LR: 0.00020374, T: 0:11:16\n",
      "[TRAIN_F0], E: 6/10, S: 839/840, L: 0.43352, LR: 0.00020009, T: 0:11:53\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F0], E: 6/10, S: 000/279, L: 0.32736, T: 0:00:00\n",
      "[VALID_F0], E: 6/10, S: 200/279, L: 0.34153, T: 0:01:30\n",
      "[VALID_F0], E: 6/10, S: 278/279, L: 0.34430, T: 0:02:03\n",
      "\n",
      "score: 0.43030138233976967\n",
      "any_severe: 0.2870458386758138\n",
      "spinal: 0.28540425395201874\n",
      "foraminal: 0.406495683388933\n",
      "subarticular: 0.4557486660144015\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 6, score: 0.43030138233976967\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 6, valid_loss: 0.3443012493608244\n",
      "\n",
      "-- [Fold: 0, Epoch: 6] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F0], E: 7/10, S: 000/840, L: 0.27555, LR: 0.00020000, T: 0:00:01\n",
      "[TRAIN_F0], E: 7/10, S: 200/840, L: 0.42031, LR: 0.00018133, T: 0:02:54\n",
      "[TRAIN_F0], E: 7/10, S: 400/840, L: 0.41215, LR: 0.00016282, T: 0:05:42\n",
      "[TRAIN_F0], E: 7/10, S: 600/840, L: 0.40926, LR: 0.00014463, T: 0:08:31\n",
      "[TRAIN_F0], E: 7/10, S: 800/840, L: 0.40508, LR: 0.00012693, T: 0:11:21\n",
      "[TRAIN_F0], E: 7/10, S: 839/840, L: 0.40531, LR: 0.00012355, T: 0:11:54\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F0], E: 7/10, S: 000/279, L: 0.35912, T: 0:00:00\n",
      "[VALID_F0], E: 7/10, S: 200/279, L: 0.34354, T: 0:01:16\n",
      "[VALID_F0], E: 7/10, S: 278/279, L: 0.34640, T: 0:01:47\n",
      "\n",
      "score: 0.44374102214685407\n",
      "any_severe: 0.3224807224936088\n",
      "spinal: 0.304461403848438\n",
      "foraminal: 0.419760578623865\n",
      "subarticular: 0.4857407843150139\n",
      "-- [Fold: 0, Epoch: 7] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F0], E: 8/10, S: 000/840, L: 0.34307, LR: 0.00012346, T: 0:00:01\n",
      "[TRAIN_F0], E: 8/10, S: 200/840, L: 0.38532, LR: 0.00010655, T: 0:02:49\n",
      "[TRAIN_F0], E: 8/10, S: 400/840, L: 0.37804, LR: 0.00009045, T: 0:05:36\n",
      "[TRAIN_F0], E: 8/10, S: 600/840, L: 0.37593, LR: 0.00007530, T: 0:08:26\n",
      "[TRAIN_F0], E: 8/10, S: 800/840, L: 0.38354, LR: 0.00006125, T: 0:11:14\n",
      "[TRAIN_F0], E: 8/10, S: 839/840, L: 0.38549, LR: 0.00005864, T: 0:11:47\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F0], E: 8/10, S: 000/279, L: 0.26610, T: 0:00:00\n",
      "[VALID_F0], E: 8/10, S: 200/279, L: 0.33308, T: 0:01:16\n",
      "[VALID_F0], E: 8/10, S: 278/279, L: 0.33622, T: 0:01:46\n",
      "\n",
      "score: 0.4175672538733376\n",
      "any_severe: 0.2773963060178014\n",
      "spinal: 0.26810825195111654\n",
      "foraminal: 0.3847240714362196\n",
      "subarticular: 0.45969849037714056\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 8, score: 0.4175672538733376\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 8, valid_loss: 0.33621997610068644\n",
      "\n",
      "-- [Fold: 0, Epoch: 8] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F0], E: 9/10, S: 000/840, L: 0.30737, LR: 0.00005858, T: 0:00:01\n",
      "[TRAIN_F0], E: 9/10, S: 200/840, L: 0.36951, LR: 0.00004599, T: 0:02:47\n",
      "[TRAIN_F0], E: 9/10, S: 400/840, L: 0.36890, LR: 0.00003475, T: 0:05:36\n",
      "[TRAIN_F0], E: 9/10, S: 600/840, L: 0.37098, LR: 0.00002496, T: 0:08:23\n",
      "[TRAIN_F0], E: 9/10, S: 800/840, L: 0.36532, LR: 0.00001669, T: 0:11:12\n",
      "[TRAIN_F0], E: 9/10, S: 839/840, L: 0.36345, LR: 0.00001526, T: 0:11:44\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F0], E: 9/10, S: 000/279, L: 0.29324, T: 0:00:00\n",
      "[VALID_F0], E: 9/10, S: 200/279, L: 0.33223, T: 0:01:16\n",
      "[VALID_F0], E: 9/10, S: 278/279, L: 0.33464, T: 0:01:46\n",
      "\n",
      "score: 0.4198067051104715\n",
      "any_severe: 0.31526613116058505\n",
      "spinal: 0.2925301187922478\n",
      "foraminal: 0.4070056857809564\n",
      "subarticular: 0.45534373680832385\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 9, valid_loss: 0.3346383421577413\n",
      "\n",
      "-- [Fold: 0, Epoch: 9] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F0], E: 10/10, S: 000/840, L: 0.67537, LR: 0.00001522, T: 0:00:01\n",
      "[TRAIN_F0], E: 10/10, S: 200/840, L: 0.34602, LR: 0.00000889, T: 0:02:47\n",
      "[TRAIN_F0], E: 10/10, S: 400/840, L: 0.33874, LR: 0.00000422, T: 0:05:33\n",
      "[TRAIN_F0], E: 10/10, S: 600/840, L: 0.34841, LR: 0.00000126, T: 0:08:23\n",
      "[TRAIN_F0], E: 10/10, S: 800/840, L: 0.35145, LR: 0.00000003, T: 0:11:10\n",
      "[TRAIN_F0], E: 10/10, S: 839/840, L: 0.35244, LR: 0.00000000, T: 0:11:43\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F0], E: 10/10, S: 000/279, L: 0.29273, T: 0:00:00\n",
      "[VALID_F0], E: 10/10, S: 200/279, L: 0.33121, T: 0:01:18\n",
      "[VALID_F0], E: 10/10, S: 278/279, L: 0.33405, T: 0:01:47\n",
      "\n",
      "score: 0.41438594325711714\n",
      "any_severe: 0.29051727631651886\n",
      "spinal: 0.27815687585220106\n",
      "foraminal: 0.393577256568289\n",
      "subarticular: 0.4475550304102631\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 10, score: 0.41438594325711714\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 10, valid_loss: 0.3340507031856898\n",
      "\n",
      "-- [Fold: 0, Epoch: 10] DONE --\n",
      "\n",
      "exp: exp164\n",
      "--- FOLD 1 ---\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F1], E: 1/10, S: 000/838, L: 1.15424, LR: 0.00000000, T: 0:00:01\n",
      "[TRAIN_F1], E: 1/10, S: 200/838, L: 1.03881, LR: 0.00004773, T: 0:02:47\n",
      "[TRAIN_F1], E: 1/10, S: 400/838, L: 0.87443, LR: 0.00009547, T: 0:05:34\n",
      "[TRAIN_F1], E: 1/10, S: 600/838, L: 0.77378, LR: 0.00014320, T: 0:08:22\n",
      "[TRAIN_F1], E: 1/10, S: 800/838, L: 0.70699, LR: 0.00019093, T: 0:11:08\n",
      "[TRAIN_F1], E: 1/10, S: 837/838, L: 0.70228, LR: 0.00019976, T: 0:11:39\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F1], E: 1/10, S: 000/280, L: 0.65254, T: 0:00:00\n",
      "[VALID_F1], E: 1/10, S: 200/280, L: 0.44126, T: 0:01:19\n",
      "[VALID_F1], E: 1/10, S: 279/280, L: 0.44962, T: 0:01:50\n",
      "\n",
      "score: 0.513339064487194\n",
      "any_severe: 0.3354113512435999\n",
      "spinal: 0.3529846621780605\n",
      "foraminal: 0.5202668243046109\n",
      "subarticular: 0.4888379937353165\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 1, score: 0.513339064487194\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 1, valid_loss: 0.44962460771868273\n",
      "\n",
      "-- [Fold: 1, Epoch: 1] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F1], E: 2/10, S: 000/838, L: 0.71435, LR: 0.00020000, T: 0:00:01\n",
      "[TRAIN_F1], E: 2/10, S: 200/838, L: 0.51117, LR: 0.00024773, T: 0:02:48\n",
      "[TRAIN_F1], E: 2/10, S: 400/838, L: 0.50704, LR: 0.00029547, T: 0:05:37\n",
      "[TRAIN_F1], E: 2/10, S: 600/838, L: 0.50371, LR: 0.00034320, T: 0:08:25\n",
      "[TRAIN_F1], E: 2/10, S: 800/838, L: 0.49564, LR: 0.00039093, T: 0:11:13\n",
      "[TRAIN_F1], E: 2/10, S: 837/838, L: 0.49609, LR: 0.00039976, T: 0:11:45\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F1], E: 2/10, S: 000/280, L: 0.62747, T: 0:00:00\n",
      "[VALID_F1], E: 2/10, S: 200/280, L: 0.41462, T: 0:01:19\n",
      "[VALID_F1], E: 2/10, S: 279/280, L: 0.42165, T: 0:01:50\n",
      "\n",
      "score: 0.57230751389282\n",
      "any_severe: 0.388316798962958\n",
      "spinal: 0.38259478184539886\n",
      "foraminal: 0.592846419090026\n",
      "subarticular: 0.5574906258131733\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 2, valid_loss: 0.4216526492764907\n",
      "\n",
      "-- [Fold: 1, Epoch: 2] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F1], E: 3/10, S: 000/838, L: 0.25351, LR: 0.00040000, T: 0:00:01\n",
      "[TRAIN_F1], E: 3/10, S: 200/838, L: 0.47729, LR: 0.00039912, T: 0:02:49\n",
      "[TRAIN_F1], E: 3/10, S: 400/838, L: 0.47987, LR: 0.00039650, T: 0:05:35\n",
      "[TRAIN_F1], E: 3/10, S: 600/838, L: 0.47655, LR: 0.00039215, T: 0:08:22\n",
      "[TRAIN_F1], E: 3/10, S: 800/838, L: 0.47425, LR: 0.00038611, T: 0:11:07\n",
      "[TRAIN_F1], E: 3/10, S: 837/838, L: 0.47388, LR: 0.00038481, T: 0:11:38\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F1], E: 3/10, S: 000/280, L: 0.61276, T: 0:00:00\n",
      "[VALID_F1], E: 3/10, S: 200/280, L: 0.38842, T: 0:01:17\n",
      "[VALID_F1], E: 3/10, S: 279/280, L: 0.39700, T: 0:01:47\n",
      "\n",
      "score: 0.47313074186082094\n",
      "any_severe: 0.35527051538535837\n",
      "spinal: 0.3320462211138478\n",
      "foraminal: 0.4836319260676755\n",
      "subarticular: 0.48585385192547687\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 3, score: 0.47313074186082094\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 3, valid_loss: 0.39699848796507076\n",
      "\n",
      "-- [Fold: 1, Epoch: 3] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F1], E: 4/10, S: 000/838, L: 0.43324, LR: 0.00038478, T: 0:00:01\n",
      "[TRAIN_F1], E: 4/10, S: 200/838, L: 0.45774, LR: 0.00037680, T: 0:02:46\n",
      "[TRAIN_F1], E: 4/10, S: 400/838, L: 0.45553, LR: 0.00036728, T: 0:05:31\n",
      "[TRAIN_F1], E: 4/10, S: 600/838, L: 0.45579, LR: 0.00035628, T: 0:08:17\n",
      "[TRAIN_F1], E: 4/10, S: 800/838, L: 0.44858, LR: 0.00034392, T: 0:11:02\n",
      "[TRAIN_F1], E: 4/10, S: 837/838, L: 0.45124, LR: 0.00034149, T: 0:11:33\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F1], E: 4/10, S: 000/280, L: 0.47419, T: 0:00:00\n",
      "[VALID_F1], E: 4/10, S: 200/280, L: 0.38542, T: 0:01:18\n",
      "[VALID_F1], E: 4/10, S: 279/280, L: 0.39397, T: 0:01:47\n",
      "\n",
      "score: 0.47173994524380064\n",
      "any_severe: 0.3176895332805116\n",
      "spinal: 0.3175991405146558\n",
      "foraminal: 0.4500850498514064\n",
      "subarticular: 0.4934852334020505\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 4, score: 0.47173994524380064\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 4, valid_loss: 0.39396936891966367\n",
      "\n",
      "-- [Fold: 1, Epoch: 4] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F1], E: 5/10, S: 000/838, L: 0.63327, LR: 0.00034142, T: 0:00:01\n",
      "[TRAIN_F1], E: 5/10, S: 200/838, L: 0.44405, LR: 0.00032757, T: 0:02:47\n",
      "[TRAIN_F1], E: 5/10, S: 400/838, L: 0.44408, LR: 0.00031259, T: 0:05:33\n",
      "[TRAIN_F1], E: 5/10, S: 600/838, L: 0.44762, LR: 0.00029663, T: 0:08:19\n",
      "[TRAIN_F1], E: 5/10, S: 800/838, L: 0.44421, LR: 0.00027981, T: 0:11:05\n",
      "[TRAIN_F1], E: 5/10, S: 837/838, L: 0.44373, LR: 0.00027662, T: 0:11:36\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F1], E: 5/10, S: 000/280, L: 0.46240, T: 0:00:00\n",
      "[VALID_F1], E: 5/10, S: 200/280, L: 0.36477, T: 0:01:17\n",
      "[VALID_F1], E: 5/10, S: 279/280, L: 0.37245, T: 0:01:48\n",
      "\n",
      "score: 0.43868379884683306\n",
      "any_severe: 0.30040700749899296\n",
      "spinal: 0.29284541646463785\n",
      "foraminal: 0.4236430763415857\n",
      "subarticular: 0.4612861123864356\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 5, score: 0.43868379884683306\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 5, valid_loss: 0.3724496230283486\n",
      "\n",
      "-- [Fold: 1, Epoch: 5] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F1], E: 6/10, S: 000/838, L: 0.61315, LR: 0.00027654, T: 0:00:01\n",
      "[TRAIN_F1], E: 6/10, S: 200/838, L: 0.43424, LR: 0.00025891, T: 0:02:46\n",
      "[TRAIN_F1], E: 6/10, S: 400/838, L: 0.42943, LR: 0.00024076, T: 0:05:31\n",
      "[TRAIN_F1], E: 6/10, S: 600/838, L: 0.42416, LR: 0.00022226, T: 0:08:16\n",
      "[TRAIN_F1], E: 6/10, S: 800/838, L: 0.42817, LR: 0.00020356, T: 0:11:01\n",
      "[TRAIN_F1], E: 6/10, S: 837/838, L: 0.42638, LR: 0.00020009, T: 0:11:32\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F1], E: 6/10, S: 000/280, L: 0.47144, T: 0:00:00\n",
      "[VALID_F1], E: 6/10, S: 200/280, L: 0.35798, T: 0:01:17\n",
      "[VALID_F1], E: 6/10, S: 279/280, L: 0.36448, T: 0:01:47\n",
      "\n",
      "score: 0.4687449753378937\n",
      "any_severe: 0.38681303209296714\n",
      "spinal: 0.35586388253618123\n",
      "foraminal: 0.4714959469666049\n",
      "subarticular: 0.49694315326596844\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 6, valid_loss: 0.3644801899990333\n",
      "\n",
      "-- [Fold: 1, Epoch: 6] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F1], E: 7/10, S: 000/838, L: 0.39229, LR: 0.00020000, T: 0:00:01\n",
      "[TRAIN_F1], E: 7/10, S: 200/838, L: 0.40730, LR: 0.00018128, T: 0:02:48\n",
      "[TRAIN_F1], E: 7/10, S: 400/838, L: 0.40489, LR: 0.00016273, T: 0:05:35\n",
      "[TRAIN_F1], E: 7/10, S: 600/838, L: 0.40938, LR: 0.00014450, T: 0:08:23\n",
      "[TRAIN_F1], E: 7/10, S: 800/838, L: 0.40759, LR: 0.00012677, T: 0:11:17\n",
      "[TRAIN_F1], E: 7/10, S: 837/838, L: 0.40632, LR: 0.00012355, T: 0:11:50\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F1], E: 7/10, S: 000/280, L: 0.50136, T: 0:00:00\n",
      "[VALID_F1], E: 7/10, S: 200/280, L: 0.35606, T: 0:01:20\n",
      "[VALID_F1], E: 7/10, S: 279/280, L: 0.36146, T: 0:01:54\n",
      "\n",
      "score: 0.4793923151066679\n",
      "any_severe: 0.4041163264565108\n",
      "spinal: 0.35496983962088635\n",
      "foraminal: 0.48856525402177164\n",
      "subarticular: 0.5193658630271887\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 7, valid_loss: 0.36145508749011374\n",
      "\n",
      "-- [Fold: 1, Epoch: 7] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F1], E: 8/10, S: 000/838, L: 0.36175, LR: 0.00012346, T: 0:00:01\n",
      "[TRAIN_F1], E: 8/10, S: 200/838, L: 0.39932, LR: 0.00010651, T: 0:02:49\n",
      "[TRAIN_F1], E: 8/10, S: 400/838, L: 0.39018, LR: 0.00009037, T: 0:05:38\n",
      "[TRAIN_F1], E: 8/10, S: 600/838, L: 0.38775, LR: 0.00007520, T: 0:08:30\n",
      "[TRAIN_F1], E: 8/10, S: 800/838, L: 0.38982, LR: 0.00006112, T: 0:11:18\n",
      "[TRAIN_F1], E: 8/10, S: 837/838, L: 0.38868, LR: 0.00005864, T: 0:11:49\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F1], E: 8/10, S: 000/280, L: 0.63197, T: 0:00:00\n",
      "[VALID_F1], E: 8/10, S: 200/280, L: 0.34814, T: 0:01:17\n",
      "[VALID_F1], E: 8/10, S: 279/280, L: 0.35633, T: 0:01:47\n",
      "\n",
      "score: 0.4389125172832168\n",
      "any_severe: 0.275465212216781\n",
      "spinal: 0.2724830236603314\n",
      "foraminal: 0.44187986573499277\n",
      "subarticular: 0.43892735738789035\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 8, valid_loss: 0.3563301649510062\n",
      "\n",
      "-- [Fold: 1, Epoch: 8] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F1], E: 9/10, S: 000/838, L: 0.74307, LR: 0.00005858, T: 0:00:01\n",
      "[TRAIN_F1], E: 9/10, S: 200/838, L: 0.35562, LR: 0.00004596, T: 0:02:46\n",
      "[TRAIN_F1], E: 9/10, S: 400/838, L: 0.36427, LR: 0.00003470, T: 0:05:32\n",
      "[TRAIN_F1], E: 9/10, S: 600/838, L: 0.36642, LR: 0.00002489, T: 0:08:16\n",
      "[TRAIN_F1], E: 9/10, S: 800/838, L: 0.36757, LR: 0.00001662, T: 0:11:02\n",
      "[TRAIN_F1], E: 9/10, S: 837/838, L: 0.36534, LR: 0.00001526, T: 0:11:33\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F1], E: 9/10, S: 000/280, L: 0.51389, T: 0:00:00\n",
      "[VALID_F1], E: 9/10, S: 200/280, L: 0.34813, T: 0:01:15\n",
      "[VALID_F1], E: 9/10, S: 279/280, L: 0.35567, T: 0:01:47\n",
      "\n",
      "score: 0.4166075932547543\n",
      "any_severe: 0.2800308909080573\n",
      "spinal: 0.26747539367197387\n",
      "foraminal: 0.4064304065890729\n",
      "subarticular: 0.43934027715651913\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 9, score: 0.4166075932547543\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 9, valid_loss: 0.355667451363323\n",
      "\n",
      "-- [Fold: 1, Epoch: 9] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F1], E: 10/10, S: 000/838, L: 0.38524, LR: 0.00001522, T: 0:00:01\n",
      "[TRAIN_F1], E: 10/10, S: 200/838, L: 0.35371, LR: 0.00000887, T: 0:02:47\n",
      "[TRAIN_F1], E: 10/10, S: 400/838, L: 0.35648, LR: 0.00000420, T: 0:05:32\n",
      "[TRAIN_F1], E: 10/10, S: 600/838, L: 0.35201, LR: 0.00000124, T: 0:08:18\n",
      "[TRAIN_F1], E: 10/10, S: 800/838, L: 0.35430, LR: 0.00000003, T: 0:11:03\n",
      "[TRAIN_F1], E: 10/10, S: 837/838, L: 0.35375, LR: 0.00000000, T: 0:11:33\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F1], E: 10/10, S: 000/280, L: 0.52281, T: 0:00:00\n",
      "[VALID_F1], E: 10/10, S: 200/280, L: 0.34105, T: 0:01:18\n",
      "[VALID_F1], E: 10/10, S: 279/280, L: 0.34877, T: 0:01:49\n",
      "\n",
      "score: 0.4151122230297611\n",
      "any_severe: 0.2652255770574949\n",
      "spinal: 0.26080215445278493\n",
      "foraminal: 0.4030996963740028\n",
      "subarticular: 0.43154817229022924\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 10, score: 0.4151122230297611\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 10, valid_loss: 0.3487667666082936\n",
      "\n",
      "-- [Fold: 1, Epoch: 10] DONE --\n",
      "\n",
      "exp: exp164\n",
      "--- FOLD 2 ---\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F2], E: 1/10, S: 000/838, L: 1.15726, LR: 0.00000000, T: 0:00:01\n",
      "[TRAIN_F2], E: 1/10, S: 200/838, L: 1.03419, LR: 0.00004773, T: 0:02:49\n",
      "[TRAIN_F2], E: 1/10, S: 400/838, L: 0.87285, LR: 0.00009547, T: 0:05:36\n",
      "[TRAIN_F2], E: 1/10, S: 600/838, L: 0.76894, LR: 0.00014320, T: 0:08:22\n",
      "[TRAIN_F2], E: 1/10, S: 800/838, L: 0.70975, LR: 0.00019093, T: 0:11:07\n",
      "[TRAIN_F2], E: 1/10, S: 837/838, L: 0.70082, LR: 0.00019976, T: 0:11:38\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F2], E: 1/10, S: 000/280, L: 0.26571, T: 0:00:00\n",
      "[VALID_F2], E: 1/10, S: 200/280, L: 0.43963, T: 0:01:17\n",
      "[VALID_F2], E: 1/10, S: 279/280, L: 0.43671, T: 0:01:47\n",
      "\n",
      "score: 0.5444414479717811\n",
      "any_severe: 0.40506099822275166\n",
      "spinal: 0.39445940110672983\n",
      "foraminal: 0.5518294232025542\n",
      "subarticular: 0.5476550698570295\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 1, score: 0.5444414479717811\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 1, valid_loss: 0.4367138597981206\n",
      "\n",
      "-- [Fold: 2, Epoch: 1] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F2], E: 2/10, S: 000/838, L: 0.24278, LR: 0.00020000, T: 0:00:01\n",
      "[TRAIN_F2], E: 2/10, S: 200/838, L: 0.48207, LR: 0.00024773, T: 0:02:46\n",
      "[TRAIN_F2], E: 2/10, S: 400/838, L: 0.50439, LR: 0.00029547, T: 0:05:33\n",
      "[TRAIN_F2], E: 2/10, S: 600/838, L: 0.49563, LR: 0.00034320, T: 0:08:21\n",
      "[TRAIN_F2], E: 2/10, S: 800/838, L: 0.49116, LR: 0.00039093, T: 0:11:08\n",
      "[TRAIN_F2], E: 2/10, S: 837/838, L: 0.48979, LR: 0.00039976, T: 0:11:38\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F2], E: 2/10, S: 000/280, L: 0.21992, T: 0:00:00\n",
      "[VALID_F2], E: 2/10, S: 200/280, L: 0.46475, T: 0:01:18\n",
      "[VALID_F2], E: 2/10, S: 279/280, L: 0.46240, T: 0:01:48\n",
      "\n",
      "score: 0.5556747880335463\n",
      "any_severe: 0.4310254367465217\n",
      "spinal: 0.4514286100530932\n",
      "foraminal: 0.5444746282075241\n",
      "subarticular: 0.546471774552997\n",
      "-- [Fold: 2, Epoch: 2] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F2], E: 3/10, S: 000/838, L: 0.41047, LR: 0.00040000, T: 0:00:01\n",
      "[TRAIN_F2], E: 3/10, S: 200/838, L: 0.47711, LR: 0.00039912, T: 0:02:48\n",
      "[TRAIN_F2], E: 3/10, S: 400/838, L: 0.46725, LR: 0.00039650, T: 0:05:36\n",
      "[TRAIN_F2], E: 3/10, S: 600/838, L: 0.47060, LR: 0.00039215, T: 0:08:24\n",
      "[TRAIN_F2], E: 3/10, S: 800/838, L: 0.46622, LR: 0.00038611, T: 0:11:13\n",
      "[TRAIN_F2], E: 3/10, S: 837/838, L: 0.46610, LR: 0.00038481, T: 0:11:44\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F2], E: 3/10, S: 000/280, L: 0.25166, T: 0:00:00\n",
      "[VALID_F2], E: 3/10, S: 200/280, L: 0.41940, T: 0:01:17\n",
      "[VALID_F2], E: 3/10, S: 279/280, L: 0.41576, T: 0:01:47\n",
      "\n",
      "score: 0.5028298988782369\n",
      "any_severe: 0.3954287850134648\n",
      "spinal: 0.38640027263825555\n",
      "foraminal: 0.49528573167662293\n",
      "subarticular: 0.5194025784550602\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 3, score: 0.5028298988782369\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 3, valid_loss: 0.41576071718175495\n",
      "\n",
      "-- [Fold: 2, Epoch: 3] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F2], E: 4/10, S: 000/838, L: 0.73441, LR: 0.00038478, T: 0:00:01\n",
      "[TRAIN_F2], E: 4/10, S: 200/838, L: 0.45514, LR: 0.00037680, T: 0:02:46\n",
      "[TRAIN_F2], E: 4/10, S: 400/838, L: 0.45297, LR: 0.00036728, T: 0:05:32\n",
      "[TRAIN_F2], E: 4/10, S: 600/838, L: 0.45658, LR: 0.00035628, T: 0:08:18\n",
      "[TRAIN_F2], E: 4/10, S: 800/838, L: 0.45519, LR: 0.00034392, T: 0:11:03\n",
      "[TRAIN_F2], E: 4/10, S: 837/838, L: 0.45407, LR: 0.00034149, T: 0:11:33\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F2], E: 4/10, S: 000/280, L: 0.22585, T: 0:00:00\n",
      "[VALID_F2], E: 4/10, S: 200/280, L: 0.40916, T: 0:01:18\n",
      "[VALID_F2], E: 4/10, S: 279/280, L: 0.40469, T: 0:01:48\n",
      "\n",
      "score: 0.48468275310853903\n",
      "any_severe: 0.37138479385630213\n",
      "spinal: 0.36010859107702964\n",
      "foraminal: 0.4721567724612764\n",
      "subarticular: 0.5084849365350741\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 4, score: 0.48468275310853903\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 4, valid_loss: 0.4046868038895939\n",
      "\n",
      "-- [Fold: 2, Epoch: 4] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F2], E: 5/10, S: 000/838, L: 0.90615, LR: 0.00034142, T: 0:00:01\n",
      "[TRAIN_F2], E: 5/10, S: 200/838, L: 0.43129, LR: 0.00032757, T: 0:02:46\n",
      "[TRAIN_F2], E: 5/10, S: 400/838, L: 0.44052, LR: 0.00031259, T: 0:05:31\n",
      "[TRAIN_F2], E: 5/10, S: 600/838, L: 0.43935, LR: 0.00029663, T: 0:08:15\n",
      "[TRAIN_F2], E: 5/10, S: 800/838, L: 0.44022, LR: 0.00027981, T: 0:11:00\n",
      "[TRAIN_F2], E: 5/10, S: 837/838, L: 0.43912, LR: 0.00027662, T: 0:11:32\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F2], E: 5/10, S: 000/280, L: 0.16246, T: 0:00:00\n",
      "[VALID_F2], E: 5/10, S: 200/280, L: 0.39361, T: 0:01:18\n",
      "[VALID_F2], E: 5/10, S: 279/280, L: 0.39162, T: 0:01:47\n",
      "\n",
      "score: 0.48299283782432767\n",
      "any_severe: 0.410817165683889\n",
      "spinal: 0.38047273392556663\n",
      "foraminal: 0.47969490187466446\n",
      "subarticular: 0.5166352055323132\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 5, score: 0.48299283782432767\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 5, valid_loss: 0.3916168258259339\n",
      "\n",
      "-- [Fold: 2, Epoch: 5] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F2], E: 6/10, S: 000/838, L: 0.49914, LR: 0.00027654, T: 0:00:01\n",
      "[TRAIN_F2], E: 6/10, S: 200/838, L: 0.43672, LR: 0.00025891, T: 0:02:47\n",
      "[TRAIN_F2], E: 6/10, S: 400/838, L: 0.43089, LR: 0.00024076, T: 0:05:37\n",
      "[TRAIN_F2], E: 6/10, S: 600/838, L: 0.42472, LR: 0.00022226, T: 0:08:23\n",
      "[TRAIN_F2], E: 6/10, S: 800/838, L: 0.42213, LR: 0.00020356, T: 0:11:09\n",
      "[TRAIN_F2], E: 6/10, S: 837/838, L: 0.42099, LR: 0.00020009, T: 0:11:40\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F2], E: 6/10, S: 000/280, L: 0.17513, T: 0:00:00\n",
      "[VALID_F2], E: 6/10, S: 200/280, L: 0.37745, T: 0:01:16\n",
      "[VALID_F2], E: 6/10, S: 279/280, L: 0.37675, T: 0:01:47\n",
      "\n",
      "score: 0.506885831703316\n",
      "any_severe: 0.4782618745634461\n",
      "spinal: 0.42675248812905275\n",
      "foraminal: 0.5107867156137664\n",
      "subarticular: 0.5544943342272589\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 6, valid_loss: 0.3767487566785089\n",
      "\n",
      "-- [Fold: 2, Epoch: 6] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F2], E: 7/10, S: 000/838, L: 0.59988, LR: 0.00020000, T: 0:00:01\n",
      "[TRAIN_F2], E: 7/10, S: 200/838, L: 0.41146, LR: 0.00018128, T: 0:02:47\n",
      "[TRAIN_F2], E: 7/10, S: 400/838, L: 0.39683, LR: 0.00016273, T: 0:05:35\n",
      "[TRAIN_F2], E: 7/10, S: 600/838, L: 0.39930, LR: 0.00014450, T: 0:08:22\n",
      "[TRAIN_F2], E: 7/10, S: 800/838, L: 0.39946, LR: 0.00012677, T: 0:11:11\n",
      "[TRAIN_F2], E: 7/10, S: 837/838, L: 0.39935, LR: 0.00012355, T: 0:11:42\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F2], E: 7/10, S: 000/280, L: 0.18266, T: 0:00:01\n",
      "[VALID_F2], E: 7/10, S: 200/280, L: 0.37600, T: 0:01:19\n",
      "[VALID_F2], E: 7/10, S: 279/280, L: 0.37485, T: 0:01:48\n",
      "\n",
      "score: 0.5120920774343221\n",
      "any_severe: 0.4287989273640676\n",
      "spinal: 0.4093867698862323\n",
      "foraminal: 0.4943660203210356\n",
      "subarticular: 0.5492302920254438\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 7, valid_loss: 0.3748517703397998\n",
      "\n",
      "-- [Fold: 2, Epoch: 7] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F2], E: 8/10, S: 000/838, L: 0.38575, LR: 0.00012346, T: 0:00:01\n",
      "[TRAIN_F2], E: 8/10, S: 200/838, L: 0.38076, LR: 0.00010651, T: 0:02:47\n",
      "[TRAIN_F2], E: 8/10, S: 400/838, L: 0.38484, LR: 0.00009037, T: 0:05:34\n",
      "[TRAIN_F2], E: 8/10, S: 600/838, L: 0.38352, LR: 0.00007520, T: 0:08:21\n",
      "[TRAIN_F2], E: 8/10, S: 800/838, L: 0.38215, LR: 0.00006112, T: 0:11:10\n",
      "[TRAIN_F2], E: 8/10, S: 837/838, L: 0.38147, LR: 0.00005864, T: 0:11:41\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F2], E: 8/10, S: 000/280, L: 0.18075, T: 0:00:00\n",
      "[VALID_F2], E: 8/10, S: 200/280, L: 0.37029, T: 0:01:17\n",
      "[VALID_F2], E: 8/10, S: 279/280, L: 0.36758, T: 0:01:47\n",
      "\n",
      "score: 0.5075444186331004\n",
      "any_severe: 0.44991694579693026\n",
      "spinal: 0.40501187511075326\n",
      "foraminal: 0.49452418667649\n",
      "subarticular: 0.5654697212758879\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 8, valid_loss: 0.36757930454664994\n",
      "\n",
      "-- [Fold: 2, Epoch: 8] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F2], E: 9/10, S: 000/838, L: 0.24265, LR: 0.00005858, T: 0:00:01\n",
      "[TRAIN_F2], E: 9/10, S: 200/838, L: 0.35307, LR: 0.00004596, T: 0:02:46\n",
      "[TRAIN_F2], E: 9/10, S: 400/838, L: 0.36212, LR: 0.00003470, T: 0:05:31\n",
      "[TRAIN_F2], E: 9/10, S: 600/838, L: 0.35972, LR: 0.00002489, T: 0:08:19\n",
      "[TRAIN_F2], E: 9/10, S: 800/838, L: 0.35610, LR: 0.00001662, T: 0:11:06\n",
      "[TRAIN_F2], E: 9/10, S: 837/838, L: 0.35619, LR: 0.00001526, T: 0:11:36\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F2], E: 9/10, S: 000/280, L: 0.16958, T: 0:00:00\n",
      "[VALID_F2], E: 9/10, S: 200/280, L: 0.36940, T: 0:01:17\n",
      "[VALID_F2], E: 9/10, S: 279/280, L: 0.36728, T: 0:01:47\n",
      "\n",
      "score: 0.47165446102250874\n",
      "any_severe: 0.39529085432360084\n",
      "spinal: 0.3624432608657604\n",
      "foraminal: 0.4586541809608907\n",
      "subarticular: 0.5175023345419673\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 9, score: 0.47165446102250874\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 9, valid_loss: 0.36727838082505126\n",
      "\n",
      "-- [Fold: 2, Epoch: 9] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F2], E: 10/10, S: 000/838, L: 0.29185, LR: 0.00001522, T: 0:00:01\n",
      "[TRAIN_F2], E: 10/10, S: 200/838, L: 0.35424, LR: 0.00000887, T: 0:02:47\n",
      "[TRAIN_F2], E: 10/10, S: 400/838, L: 0.34777, LR: 0.00000420, T: 0:05:35\n",
      "[TRAIN_F2], E: 10/10, S: 600/838, L: 0.34698, LR: 0.00000124, T: 0:08:20\n",
      "[TRAIN_F2], E: 10/10, S: 800/838, L: 0.34734, LR: 0.00000003, T: 0:11:07\n",
      "[TRAIN_F2], E: 10/10, S: 837/838, L: 0.34800, LR: 0.00000000, T: 0:11:38\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F2], E: 10/10, S: 000/280, L: 0.18251, T: 0:00:00\n",
      "[VALID_F2], E: 10/10, S: 200/280, L: 0.36718, T: 0:01:16\n",
      "[VALID_F2], E: 10/10, S: 279/280, L: 0.36497, T: 0:01:46\n",
      "\n",
      "score: 0.48032432108122336\n",
      "any_severe: 0.4060424979066224\n",
      "spinal: 0.3716488660689161\n",
      "foraminal: 0.47575048336083975\n",
      "subarticular: 0.5192917906393133\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 10, valid_loss: 0.36497102190208225\n",
      "\n",
      "-- [Fold: 2, Epoch: 10] DONE --\n",
      "\n",
      "exp: exp164\n",
      "--- FOLD 3 ---\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F3], E: 1/10, S: 000/838, L: 1.16064, LR: 0.00000000, T: 0:00:01\n",
      "[TRAIN_F3], E: 1/10, S: 200/838, L: 1.03942, LR: 0.00004773, T: 0:02:46\n",
      "[TRAIN_F3], E: 1/10, S: 400/838, L: 0.87710, LR: 0.00009547, T: 0:05:32\n",
      "[TRAIN_F3], E: 1/10, S: 600/838, L: 0.77631, LR: 0.00014320, T: 0:08:17\n",
      "[TRAIN_F3], E: 1/10, S: 800/838, L: 0.71531, LR: 0.00019093, T: 0:11:02\n",
      "[TRAIN_F3], E: 1/10, S: 837/838, L: 0.70756, LR: 0.00019976, T: 0:11:33\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F3], E: 1/10, S: 000/280, L: 0.45794, T: 0:00:00\n",
      "[VALID_F3], E: 1/10, S: 200/280, L: 0.42789, T: 0:01:17\n",
      "[VALID_F3], E: 1/10, S: 279/280, L: 0.43445, T: 0:01:47\n",
      "\n",
      "score: 0.5561826873815132\n",
      "any_severe: 0.404130771404841\n",
      "spinal: 0.41147042447491056\n",
      "foraminal: 0.5258329532536128\n",
      "subarticular: 0.5791927684393441\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 1, score: 0.5561826873815132\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 1, valid_loss: 0.43444541498486483\n",
      "\n",
      "-- [Fold: 3, Epoch: 1] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F3], E: 2/10, S: 000/838, L: 0.70165, LR: 0.00020000, T: 0:00:01\n",
      "[TRAIN_F3], E: 2/10, S: 200/838, L: 0.53544, LR: 0.00024773, T: 0:02:47\n",
      "[TRAIN_F3], E: 2/10, S: 400/838, L: 0.49959, LR: 0.00029547, T: 0:05:32\n",
      "[TRAIN_F3], E: 2/10, S: 600/838, L: 0.49514, LR: 0.00034320, T: 0:08:17\n",
      "[TRAIN_F3], E: 2/10, S: 800/838, L: 0.49115, LR: 0.00039093, T: 0:11:02\n",
      "[TRAIN_F3], E: 2/10, S: 837/838, L: 0.49193, LR: 0.00039976, T: 0:11:32\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F3], E: 2/10, S: 000/280, L: 0.41453, T: 0:00:00\n",
      "[VALID_F3], E: 2/10, S: 200/280, L: 0.41551, T: 0:01:17\n",
      "[VALID_F3], E: 2/10, S: 279/280, L: 0.42354, T: 0:01:46\n",
      "\n",
      "score: 0.5037887390040031\n",
      "any_severe: 0.37856518501336034\n",
      "spinal: 0.37354551280086146\n",
      "foraminal: 0.48059055352903696\n",
      "subarticular: 0.5320065966914681\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 2, score: 0.5037887390040031\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 2, valid_loss: 0.4235388472676277\n",
      "\n",
      "-- [Fold: 3, Epoch: 2] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F3], E: 3/10, S: 000/838, L: 0.55689, LR: 0.00040000, T: 0:00:01\n",
      "[TRAIN_F3], E: 3/10, S: 200/838, L: 0.47381, LR: 0.00039912, T: 0:02:48\n",
      "[TRAIN_F3], E: 3/10, S: 400/838, L: 0.48030, LR: 0.00039650, T: 0:05:35\n",
      "[TRAIN_F3], E: 3/10, S: 600/838, L: 0.47473, LR: 0.00039215, T: 0:08:21\n",
      "[TRAIN_F3], E: 3/10, S: 800/838, L: 0.46760, LR: 0.00038611, T: 0:11:07\n",
      "[TRAIN_F3], E: 3/10, S: 837/838, L: 0.46993, LR: 0.00038481, T: 0:11:37\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F3], E: 3/10, S: 000/280, L: 0.47929, T: 0:00:00\n",
      "[VALID_F3], E: 3/10, S: 200/280, L: 0.39692, T: 0:01:16\n",
      "[VALID_F3], E: 3/10, S: 279/280, L: 0.40335, T: 0:01:47\n",
      "\n",
      "score: 0.5459157221429435\n",
      "any_severe: 0.4364724601010173\n",
      "spinal: 0.4054358425944087\n",
      "foraminal: 0.5402859058832852\n",
      "subarticular: 0.5825821559092105\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 3, valid_loss: 0.403351732556309\n",
      "\n",
      "-- [Fold: 3, Epoch: 3] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F3], E: 4/10, S: 000/838, L: 0.55168, LR: 0.00038478, T: 0:00:01\n",
      "[TRAIN_F3], E: 4/10, S: 200/838, L: 0.44280, LR: 0.00037680, T: 0:02:46\n",
      "[TRAIN_F3], E: 4/10, S: 400/838, L: 0.45365, LR: 0.00036728, T: 0:05:31\n",
      "[TRAIN_F3], E: 4/10, S: 600/838, L: 0.46094, LR: 0.00035628, T: 0:08:17\n",
      "[TRAIN_F3], E: 4/10, S: 800/838, L: 0.45736, LR: 0.00034392, T: 0:11:02\n",
      "[TRAIN_F3], E: 4/10, S: 837/838, L: 0.45745, LR: 0.00034149, T: 0:11:34\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F3], E: 4/10, S: 000/280, L: 0.35162, T: 0:00:00\n",
      "[VALID_F3], E: 4/10, S: 200/280, L: 0.39546, T: 0:01:17\n",
      "[VALID_F3], E: 4/10, S: 279/280, L: 0.40307, T: 0:01:48\n",
      "\n",
      "score: 0.5114810290135354\n",
      "any_severe: 0.3374004502034839\n",
      "spinal: 0.3320149168305233\n",
      "foraminal: 0.47541985819401666\n",
      "subarticular: 0.5529277332060148\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 4, valid_loss: 0.40307390045906816\n",
      "\n",
      "-- [Fold: 3, Epoch: 4] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F3], E: 5/10, S: 000/838, L: 0.58583, LR: 0.00034142, T: 0:00:01\n",
      "[TRAIN_F3], E: 5/10, S: 200/838, L: 0.43843, LR: 0.00032757, T: 0:02:48\n",
      "[TRAIN_F3], E: 5/10, S: 400/838, L: 0.45168, LR: 0.00031259, T: 0:05:40\n",
      "[TRAIN_F3], E: 5/10, S: 600/838, L: 0.44042, LR: 0.00029663, T: 0:08:27\n",
      "[TRAIN_F3], E: 5/10, S: 800/838, L: 0.43799, LR: 0.00027981, T: 0:11:13\n",
      "[TRAIN_F3], E: 5/10, S: 837/838, L: 0.43832, LR: 0.00027662, T: 0:11:45\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F3], E: 5/10, S: 000/280, L: 0.39810, T: 0:00:00\n",
      "[VALID_F3], E: 5/10, S: 200/280, L: 0.36897, T: 0:01:17\n",
      "[VALID_F3], E: 5/10, S: 279/280, L: 0.37422, T: 0:01:48\n",
      "\n",
      "score: 0.4764048105684193\n",
      "any_severe: 0.33884858624162834\n",
      "spinal: 0.33177232738924545\n",
      "foraminal: 0.4457852305618085\n",
      "subarticular: 0.514100649427413\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 5, score: 0.4764048105684193\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 5, valid_loss: 0.3742202818127615\n",
      "\n",
      "-- [Fold: 3, Epoch: 5] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F3], E: 6/10, S: 000/838, L: 0.51783, LR: 0.00027654, T: 0:00:01\n",
      "[TRAIN_F3], E: 6/10, S: 200/838, L: 0.43884, LR: 0.00025891, T: 0:02:47\n",
      "[TRAIN_F3], E: 6/10, S: 400/838, L: 0.43196, LR: 0.00024076, T: 0:05:37\n",
      "[TRAIN_F3], E: 6/10, S: 600/838, L: 0.43181, LR: 0.00022226, T: 0:08:24\n",
      "[TRAIN_F3], E: 6/10, S: 800/838, L: 0.42341, LR: 0.00020356, T: 0:11:13\n",
      "[TRAIN_F3], E: 6/10, S: 837/838, L: 0.42390, LR: 0.00020009, T: 0:11:43\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F3], E: 6/10, S: 000/280, L: 0.38570, T: 0:00:00\n",
      "[VALID_F3], E: 6/10, S: 200/280, L: 0.37223, T: 0:01:18\n",
      "[VALID_F3], E: 6/10, S: 279/280, L: 0.37578, T: 0:01:47\n",
      "\n",
      "score: 0.46388707320161365\n",
      "any_severe: 0.3102318265463751\n",
      "spinal: 0.3036361901449095\n",
      "foraminal: 0.4450996453291399\n",
      "subarticular: 0.4892701374755529\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 6, score: 0.46388707320161365\n",
      "\n",
      "-- [Fold: 3, Epoch: 6] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F3], E: 7/10, S: 000/838, L: 0.50403, LR: 0.00020000, T: 0:00:01\n",
      "[TRAIN_F3], E: 7/10, S: 200/838, L: 0.40865, LR: 0.00018128, T: 0:02:51\n",
      "[TRAIN_F3], E: 7/10, S: 400/838, L: 0.40948, LR: 0.00016273, T: 0:05:39\n",
      "[TRAIN_F3], E: 7/10, S: 600/838, L: 0.41167, LR: 0.00014450, T: 0:08:25\n",
      "[TRAIN_F3], E: 7/10, S: 800/838, L: 0.40805, LR: 0.00012677, T: 0:11:10\n",
      "[TRAIN_F3], E: 7/10, S: 837/838, L: 0.40717, LR: 0.00012355, T: 0:11:41\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F3], E: 7/10, S: 000/280, L: 0.34008, T: 0:00:00\n",
      "[VALID_F3], E: 7/10, S: 200/280, L: 0.36126, T: 0:01:18\n",
      "[VALID_F3], E: 7/10, S: 279/280, L: 0.36576, T: 0:01:49\n",
      "\n",
      "score: 0.4672288596992813\n",
      "any_severe: 0.35849620896071677\n",
      "spinal: 0.34005746768057504\n",
      "foraminal: 0.4436730062677126\n",
      "subarticular: 0.5092234544109917\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 7, valid_loss: 0.36576146439516116\n",
      "\n",
      "-- [Fold: 3, Epoch: 7] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F3], E: 8/10, S: 000/838, L: 0.44919, LR: 0.00012346, T: 0:00:01\n",
      "[TRAIN_F3], E: 8/10, S: 200/838, L: 0.38010, LR: 0.00010651, T: 0:02:47\n",
      "[TRAIN_F3], E: 8/10, S: 400/838, L: 0.38047, LR: 0.00009037, T: 0:05:34\n",
      "[TRAIN_F3], E: 8/10, S: 600/838, L: 0.38285, LR: 0.00007520, T: 0:08:20\n",
      "[TRAIN_F3], E: 8/10, S: 800/838, L: 0.38000, LR: 0.00006112, T: 0:11:07\n",
      "[TRAIN_F3], E: 8/10, S: 837/838, L: 0.37993, LR: 0.00005864, T: 0:11:37\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F3], E: 8/10, S: 000/280, L: 0.35330, T: 0:00:00\n",
      "[VALID_F3], E: 8/10, S: 200/280, L: 0.35880, T: 0:01:18\n",
      "[VALID_F3], E: 8/10, S: 279/280, L: 0.36269, T: 0:01:48\n",
      "\n",
      "score: 0.46259436770076123\n",
      "any_severe: 0.3063327814714099\n",
      "spinal: 0.3005651730392273\n",
      "foraminal: 0.4399884673510416\n",
      "subarticular: 0.4909678764826635\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 8, score: 0.46259436770076123\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 8, valid_loss: 0.36269048449051167\n",
      "\n",
      "-- [Fold: 3, Epoch: 8] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F3], E: 9/10, S: 000/838, L: 0.56438, LR: 0.00005858, T: 0:00:01\n",
      "[TRAIN_F3], E: 9/10, S: 200/838, L: 0.36563, LR: 0.00004596, T: 0:02:48\n",
      "[TRAIN_F3], E: 9/10, S: 400/838, L: 0.36717, LR: 0.00003470, T: 0:05:34\n",
      "[TRAIN_F3], E: 9/10, S: 600/838, L: 0.36775, LR: 0.00002489, T: 0:08:21\n",
      "[TRAIN_F3], E: 9/10, S: 800/838, L: 0.36102, LR: 0.00001662, T: 0:11:08\n",
      "[TRAIN_F3], E: 9/10, S: 837/838, L: 0.36049, LR: 0.00001526, T: 0:11:39\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F3], E: 9/10, S: 000/280, L: 0.33605, T: 0:00:00\n",
      "[VALID_F3], E: 9/10, S: 200/280, L: 0.35743, T: 0:01:17\n",
      "[VALID_F3], E: 9/10, S: 279/280, L: 0.36018, T: 0:01:48\n",
      "\n",
      "score: 0.46343308292800955\n",
      "any_severe: 0.3302925754279852\n",
      "spinal: 0.31672746453972445\n",
      "foraminal: 0.44039971854833365\n",
      "subarticular: 0.5000315581959462\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 9, valid_loss: 0.3601765420953078\n",
      "\n",
      "-- [Fold: 3, Epoch: 9] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F3], E: 10/10, S: 000/838, L: 0.21290, LR: 0.00001522, T: 0:00:01\n",
      "[TRAIN_F3], E: 10/10, S: 200/838, L: 0.34525, LR: 0.00000887, T: 0:02:47\n",
      "[TRAIN_F3], E: 10/10, S: 400/838, L: 0.34127, LR: 0.00000420, T: 0:05:34\n",
      "[TRAIN_F3], E: 10/10, S: 600/838, L: 0.34952, LR: 0.00000124, T: 0:08:21\n",
      "[TRAIN_F3], E: 10/10, S: 800/838, L: 0.34834, LR: 0.00000003, T: 0:11:07\n",
      "[TRAIN_F3], E: 10/10, S: 837/838, L: 0.34886, LR: 0.00000000, T: 0:11:38\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F3], E: 10/10, S: 000/280, L: 0.33960, T: 0:00:00\n",
      "[VALID_F3], E: 10/10, S: 200/280, L: 0.35750, T: 0:01:18\n",
      "[VALID_F3], E: 10/10, S: 279/280, L: 0.36010, T: 0:01:48\n",
      "\n",
      "score: 0.4601192799007985\n",
      "any_severe: 0.3111423087607367\n",
      "spinal: 0.3057105853331412\n",
      "foraminal: 0.43261562078177146\n",
      "subarticular: 0.49305466244742086\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 10, score: 0.4601192799007985\n",
      "\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 10, valid_loss: 0.36009861416449507\n",
      "\n",
      "-- [Fold: 3, Epoch: 10] DONE --\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707798</td>\n",
       "      <td>0.417896</td>\n",
       "      <td>0.595719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497835</td>\n",
       "      <td>0.386945</td>\n",
       "      <td>0.469837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.489835</td>\n",
       "      <td>0.380442</td>\n",
       "      <td>0.469765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.459858</td>\n",
       "      <td>0.362411</td>\n",
       "      <td>0.459455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.444063</td>\n",
       "      <td>0.373686</td>\n",
       "      <td>0.512106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.433518</td>\n",
       "      <td>0.344301</td>\n",
       "      <td>0.430301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.405309</td>\n",
       "      <td>0.346397</td>\n",
       "      <td>0.443741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.385494</td>\n",
       "      <td>0.336220</td>\n",
       "      <td>0.417567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.363452</td>\n",
       "      <td>0.334638</td>\n",
       "      <td>0.419807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.352443</td>\n",
       "      <td>0.334051</td>\n",
       "      <td>0.414386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.702278</td>\n",
       "      <td>0.449625</td>\n",
       "      <td>0.513339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.496086</td>\n",
       "      <td>0.421653</td>\n",
       "      <td>0.572308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.473879</td>\n",
       "      <td>0.396998</td>\n",
       "      <td>0.473131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.451239</td>\n",
       "      <td>0.393969</td>\n",
       "      <td>0.471740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.443733</td>\n",
       "      <td>0.372450</td>\n",
       "      <td>0.438684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.426376</td>\n",
       "      <td>0.364480</td>\n",
       "      <td>0.468745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.406318</td>\n",
       "      <td>0.361455</td>\n",
       "      <td>0.479392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.388676</td>\n",
       "      <td>0.356330</td>\n",
       "      <td>0.438913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.365337</td>\n",
       "      <td>0.355667</td>\n",
       "      <td>0.416608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.353751</td>\n",
       "      <td>0.348767</td>\n",
       "      <td>0.415112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700824</td>\n",
       "      <td>0.436714</td>\n",
       "      <td>0.544441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.489788</td>\n",
       "      <td>0.462403</td>\n",
       "      <td>0.555675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.466100</td>\n",
       "      <td>0.415761</td>\n",
       "      <td>0.502830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.454067</td>\n",
       "      <td>0.404687</td>\n",
       "      <td>0.484683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.439120</td>\n",
       "      <td>0.391617</td>\n",
       "      <td>0.482993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.420990</td>\n",
       "      <td>0.376749</td>\n",
       "      <td>0.506886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.399348</td>\n",
       "      <td>0.374852</td>\n",
       "      <td>0.512092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.381471</td>\n",
       "      <td>0.367579</td>\n",
       "      <td>0.507544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.356195</td>\n",
       "      <td>0.367278</td>\n",
       "      <td>0.471654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.347997</td>\n",
       "      <td>0.364971</td>\n",
       "      <td>0.480324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707559</td>\n",
       "      <td>0.434445</td>\n",
       "      <td>0.556183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.491932</td>\n",
       "      <td>0.423539</td>\n",
       "      <td>0.503789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.469933</td>\n",
       "      <td>0.403352</td>\n",
       "      <td>0.545916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.457446</td>\n",
       "      <td>0.403074</td>\n",
       "      <td>0.511481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.438316</td>\n",
       "      <td>0.374220</td>\n",
       "      <td>0.476405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.423903</td>\n",
       "      <td>0.375776</td>\n",
       "      <td>0.463887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.407171</td>\n",
       "      <td>0.365761</td>\n",
       "      <td>0.467229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.379929</td>\n",
       "      <td>0.362690</td>\n",
       "      <td>0.462594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.360485</td>\n",
       "      <td>0.360177</td>\n",
       "      <td>0.463433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.348863</td>\n",
       "      <td>0.360099</td>\n",
       "      <td>0.460119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold  epoch  train_loss  valid_loss     score\n",
       "0      0      0    0.707798    0.417896  0.595719\n",
       "1      0      1    0.497835    0.386945  0.469837\n",
       "2      0      2    0.489835    0.380442  0.469765\n",
       "3      0      3    0.459858    0.362411  0.459455\n",
       "4      0      4    0.444063    0.373686  0.512106\n",
       "5      0      5    0.433518    0.344301  0.430301\n",
       "6      0      6    0.405309    0.346397  0.443741\n",
       "7      0      7    0.385494    0.336220  0.417567\n",
       "8      0      8    0.363452    0.334638  0.419807\n",
       "9      0      9    0.352443    0.334051  0.414386\n",
       "10     1      0    0.702278    0.449625  0.513339\n",
       "11     1      1    0.496086    0.421653  0.572308\n",
       "12     1      2    0.473879    0.396998  0.473131\n",
       "13     1      3    0.451239    0.393969  0.471740\n",
       "14     1      4    0.443733    0.372450  0.438684\n",
       "15     1      5    0.426376    0.364480  0.468745\n",
       "16     1      6    0.406318    0.361455  0.479392\n",
       "17     1      7    0.388676    0.356330  0.438913\n",
       "18     1      8    0.365337    0.355667  0.416608\n",
       "19     1      9    0.353751    0.348767  0.415112\n",
       "20     2      0    0.700824    0.436714  0.544441\n",
       "21     2      1    0.489788    0.462403  0.555675\n",
       "22     2      2    0.466100    0.415761  0.502830\n",
       "23     2      3    0.454067    0.404687  0.484683\n",
       "24     2      4    0.439120    0.391617  0.482993\n",
       "25     2      5    0.420990    0.376749  0.506886\n",
       "26     2      6    0.399348    0.374852  0.512092\n",
       "27     2      7    0.381471    0.367579  0.507544\n",
       "28     2      8    0.356195    0.367278  0.471654\n",
       "29     2      9    0.347997    0.364971  0.480324\n",
       "30     3      0    0.707559    0.434445  0.556183\n",
       "31     3      1    0.491932    0.423539  0.503789\n",
       "32     3      2    0.469933    0.403352  0.545916\n",
       "33     3      3    0.457446    0.403074  0.511481\n",
       "34     3      4    0.438316    0.374220  0.476405\n",
       "35     3      5    0.423903    0.375776  0.463887\n",
       "36     3      6    0.407171    0.365761  0.467229\n",
       "37     3      7    0.379929    0.362690  0.462594\n",
       "38     3      8    0.360485    0.360177  0.463433\n",
       "39     3      9    0.348863    0.360099  0.460119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.352443</td>\n",
       "      <td>0.334051</td>\n",
       "      <td>0.414386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.353751</td>\n",
       "      <td>0.348767</td>\n",
       "      <td>0.415112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.356195</td>\n",
       "      <td>0.367278</td>\n",
       "      <td>0.471654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.348863</td>\n",
       "      <td>0.360099</td>\n",
       "      <td>0.460119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  epoch  train_loss  valid_loss     score\n",
       "0     0      9    0.352443    0.334051  0.414386\n",
       "1     1      9    0.353751    0.348767  0.415112\n",
       "2     2      8    0.356195    0.367278  0.471654\n",
       "3     3      9    0.348863    0.360099  0.460119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_training(CONF, train_df, debug_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e358003",
   "metadata": {
    "papermill": {
     "duration": 0.047526,
     "end_time": "2024-09-24T00:52:17.872064",
     "exception": false,
     "start_time": "2024-09-24T00:52:17.824538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "datasetId": 5484394,
     "sourceId": 9088952,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 192332916,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33124.764475,
   "end_time": "2024-09-24T00:52:20.571046",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-23T15:40:15.806571",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "634f740c1994434883bd17ead209e39e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c1c7f29fc60342bb81e5f496c8559a51",
       "placeholder": "",
       "style": "IPY_MODEL_badf6ba7f68d4a398b9cbc9c06171096",
       "value": "86.5M/86.5M[00:02&lt;00:00,68.8MB/s]"
      }
     },
     "65c7de0ea6e647cdad8f1acd88a7caef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76a6228ac2a741c0a34a19c8ba345990": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d7518d576dbb454eb87f10ee2fcd02fa",
       "placeholder": "",
       "style": "IPY_MODEL_abd39706b298466a8836be0c5460a237",
       "value": "model.safetensors:100%"
      }
     },
     "7e6639da688747a99f4af8e657f960c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_76a6228ac2a741c0a34a19c8ba345990",
        "IPY_MODEL_8265df5f294840a79a09d7c78ab6ed8d",
        "IPY_MODEL_634f740c1994434883bd17ead209e39e"
       ],
       "layout": "IPY_MODEL_84bca1f52b1146eda22a200089168347"
      }
     },
     "8265df5f294840a79a09d7c78ab6ed8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_65c7de0ea6e647cdad8f1acd88a7caef",
       "max": 86523256.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dcd8aa41fe24452582dd432be8075b86",
       "value": 86523256.0
      }
     },
     "84bca1f52b1146eda22a200089168347": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "abd39706b298466a8836be0c5460a237": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "badf6ba7f68d4a398b9cbc9c06171096": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c1c7f29fc60342bb81e5f496c8559a51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d7518d576dbb454eb87f10ee2fcd02fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcd8aa41fe24452582dd432be8075b86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
